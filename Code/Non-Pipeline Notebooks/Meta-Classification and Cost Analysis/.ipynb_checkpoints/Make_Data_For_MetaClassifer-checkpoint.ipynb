{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/courtneycochrane/anaconda/envs/py27/lib/python2.7/site-packages/nbformat/current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import current\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = current.read(f, 'json')\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.worksheets[0].cells:\n",
    "                if cell.cell_type == 'code' and cell.language == 'python':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.input)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from MergeDiagnosis_AdjustedLabels.ipynb\n",
      "importing Jupyter notebook from LongitudinalDataAnalysis.ipynb\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Categorical_Updated.ipynb\n",
      "importing Jupyter notebook from Imputation.ipynb\n",
      "importing Jupyter notebook from FeatureReduction.ipynb\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from SupervisedLearning.ipynb\n",
      "importing Jupyter notebook from ModelPerformance.ipynb\n",
      "importing Jupyter notebook from TrainTestSplit.ipynb\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy\n",
    "import pandas\n",
    "import csv\n",
    "import MergeDiagnosis_AdjustedLabels\n",
    "import LongitudinalDataAnalysis\n",
    "import Categorical_Updated\n",
    "import Imputation\n",
    "import FeatureReduction\n",
    "import SupervisedLearning\n",
    "import ModelPerformance\n",
    "import TrainTestSplit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Merge Data\n",
    "# -------------------------------\n",
    "merged_data = MergeDiagnosis_AdjustedLabels.data_preprocess(study = \"all\",imaging_to_drop = 'all', reversions = 'label0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columsn that are one-hot encoded\n",
      "-------------------------------------\n",
      "['VISCODE', 'COLPROT', 'ORIGPROT', 'DX_bl', 'PTGENDER', 'PTETHCAT', 'PTRACCAT', 'PTMARRY']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Categorical to Numerical\n",
    "# -------------------------------\n",
    "date_cols = ['update_stamp','EXAMDATE','EXAMDATE_bl']\n",
    "cols_to_ignore = ['PTID']\n",
    "\n",
    "Categorical_Updated.categorical_conversion(date_cols,cols_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RID</th>\n",
       "      <th>SITE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>ADAS11</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>...</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>PTRACCAT_Unknown</th>\n",
       "      <th>PTRACCAT_White</th>\n",
       "      <th>PTMARRY_Married</th>\n",
       "      <th>PTMARRY_Never married</th>\n",
       "      <th>PTMARRY_Unknown</th>\n",
       "      <th>PTMARRY_Widowed</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>74.3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.67</td>\n",
       "      <td>18.67</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>81.3</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>22.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>81.3</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  RID  SITE   AGE  PTEDUCAT  APOE4  CDRSB  ADAS11  ADAS13  MMSE  \\\n",
       "0           0    2    11  74.3        16    0.0    0.0   10.67   18.67  28.0   \n",
       "1           1    3    11  81.3        18    1.0    4.5   22.00   31.00  20.0   \n",
       "2           2    3    11  81.3        18    1.0    6.0   19.00   30.00  24.0   \n",
       "\n",
       "  ...  PTRACCAT_Black  PTRACCAT_Hawaiian/Other PI  PTRACCAT_More than one  \\\n",
       "0 ...             0.0                         0.0                     0.0   \n",
       "1 ...             0.0                         0.0                     0.0   \n",
       "2 ...             0.0                         0.0                     0.0   \n",
       "\n",
       "   PTRACCAT_Unknown  PTRACCAT_White  PTMARRY_Married  PTMARRY_Never married  \\\n",
       "0               0.0             1.0              1.0                    0.0   \n",
       "1               0.0             1.0              1.0                    0.0   \n",
       "2               0.0             1.0              1.0                    0.0   \n",
       "\n",
       "   PTMARRY_Unknown  PTMARRY_Widowed  AD  \n",
       "0              0.0              0.0   0  \n",
       "1              0.0              0.0   1  \n",
       "2              0.0              0.0   1  \n",
       "\n",
       "[3 rows x 104 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix Size:\n",
      "-----------------------\n",
      "(12736, 104)\n",
      " \n",
      "Identified columns of interest in input file: \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Patient RID column: [1]\n",
      "Demo columns: [  3   4  90  91  92  93  94  95  96  97  98  99 100 101 102]\n",
      "BaselineOneTime columns: [ 5 54 84 85]\n",
      "BaselineEvaluation columns: [30 31 32 33 35 36 37 34 38 39 41 42 43 44 45 40 46 48 49 50 51 52 47 53]\n",
      "Time columns: [ 2 56 57 58 59 60 82 83 55]\n",
      "CurrentEvaluation columns: [ 6  7  8  9 11 12 13 10 14 15 17 18 19 20 21 16 22 24 25 26 27 28 23 29]\n",
      "CurrentDiagnosis columns: [103]\n",
      "------\n",
      "Method 2 for Longitudinal Data Analysis\n",
      "------\n",
      " \n",
      "New Input Matrix Size:\n",
      "-----------------------\n",
      "(1737, 115)\n",
      " \n",
      "New Output Matrix Size:\n",
      "-----------------------\n",
      "(1737,)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Longitudinal Data Analysis\n",
    "# -------------------------------\n",
    "\n",
    "# Input file name for Longitudinal Data Analysis\n",
    "InputToLongitudinal='CategoricalToNumerical.csv'\n",
    "\n",
    "with open(InputToLongitudinal) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    labels = next(reader)\n",
    "\n",
    "# Output file name from this script\n",
    "OutputFromLongitudinal='LongitudinalDataAnalysis.csv'\n",
    "\n",
    "# Patient RID Features\n",
    "Patient_FEATURES=['RID'];\n",
    "\n",
    "# Demographic Features\n",
    "Demo_FEATURES_type=['AGE','PTEDUCAT','PTGENDER','PTETHCAT','PTRACCAT','PTMARRY']\n",
    "Demo_FEATURES = []\n",
    "for i in labels:\n",
    "    if i in Demo_FEATURES_type:\n",
    "        Demo_FEATURES.append(i)\n",
    "    elif i.find(\"_\") != -1 and i[:i.find(\"_\")] in Demo_FEATURES_type:\n",
    "        Demo_FEATURES.append(i)\n",
    "    \n",
    "# Baseline OneTime Features\n",
    "BaselineOneTime_FEATURES_type = ['APOE4','Years_bl','ORIGPROT']\n",
    "BaselineOneTime_FEATURES = []\n",
    "for i in labels:\n",
    "    if i in BaselineOneTime_FEATURES_type:\n",
    "        BaselineOneTime_FEATURES.append(i)\n",
    "    elif i.rfind(\"_\") != -1 and i[:i.rfind(\"_\")] in BaselineOneTime_FEATURES_type:\n",
    "        BaselineOneTime_FEATURES.append(i)\n",
    "        \n",
    "# Time Headers\n",
    "Time_FEATURES_type=['SITE','Month','update_stamp_minus_EXAMDATE_bl','update_stamp_minus_EXAMDATE','EXAMDATE_minus_EXAMDATE_bl',\n",
    "               'COLPROT','M','Month_bl']\n",
    "Time_FEATURES = []\n",
    "for i in labels:\n",
    "    if i in Time_FEATURES_type:\n",
    "        Time_FEATURES.append(i)\n",
    "    elif i.find(\"_\") != -1 and i[:i.find(\"_\")] in Time_FEATURES_type:\n",
    "        Time_FEATURES.append(i)\n",
    "Time_FEATURES.insert(len(Time_FEATURES), Time_FEATURES.pop(Time_FEATURES.index('Month_bl'))) # Month_bl must be last feature in this list\n",
    "\n",
    "        \n",
    "# Baseline Evaluation Features\n",
    "BaselineEvaluation_FEATURES=['CDRSB_bl','ADAS11_bl','ADAS13_bl','MMSE_bl','RAVLT_learning_bl','RAVLT_forgetting_bl',\n",
    "                             'RAVLT_perc_forgetting_bl','RAVLT_immediate_bl','FAQ_bl','MOCA_bl','EcogPtLang_bl','EcogPtVisspat_bl',\n",
    "                             'EcogPtPlan_bl','EcogPtOrgan_bl','EcogPtDivatt_bl','EcogPtMem_bl','EcogPtTotal_bl','EcogSPLang_bl',\n",
    "                             'EcogSPVisspat_bl','EcogSPPlan_bl','EcogSPOrgan_bl','EcogSPDivatt_bl','EcogSPMem_bl','EcogSPTotal_bl'];\n",
    "\n",
    "\n",
    "   \n",
    "# Current Medical Evaluation\n",
    "CurrentEvaluation_FEATURES=['CDRSB','ADAS11','ADAS13','MMSE','RAVLT_learning','RAVLT_forgetting','RAVLT_perc_forgetting','RAVLT_immediate',\n",
    "                            'FAQ','MOCA','EcogPtLang','EcogPtVisspat','EcogPtPlan','EcogPtOrgan','EcogPtDivatt','EcogPtMem','EcogPtTotal',\n",
    "                            'EcogSPLang','EcogSPVisspat','EcogSPPlan','EcogSPOrgan','EcogSPDivatt','EcogSPMem','EcogSPTotal'];\n",
    "\n",
    "\n",
    "# Current Diagnosis\n",
    "CurrentDiagnosis_FEATURES= ['AD'];\n",
    "\n",
    "# Longitudinal Method\n",
    "LongitudinalMethod=2;\n",
    "MetricList=['MaxTime','Delta','Mean','Std'];\n",
    "\n",
    "# Run Longitudinal Data Anaysis\n",
    "LongitudinalDataAnalysis.runLongitudinal(InputToLongitudinal,OutputFromLongitudinal,Patient_FEATURES,Demo_FEATURES,\\\n",
    "                                         BaselineOneTime_FEATURES,Time_FEATURES,BaselineEvaluation_FEATURES,\\\n",
    "                                         CurrentEvaluation_FEATURES,CurrentDiagnosis_FEATURES,LongitudinalMethod,MetricList)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTGENDER_Male</th>\n",
       "      <th>PTETHCAT_Not Hisp/Latino</th>\n",
       "      <th>PTETHCAT_Unknown</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>PTRACCAT_Unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>EcogSPDivatt_Std</th>\n",
       "      <th>EcogSPMem_MaxTime</th>\n",
       "      <th>EcogSPMem_Delta</th>\n",
       "      <th>EcogSPMem_Mean</th>\n",
       "      <th>EcogSPMem_Std</th>\n",
       "      <th>EcogSPTotal_MaxTime</th>\n",
       "      <th>EcogSPTotal_Delta</th>\n",
       "      <th>EcogSPTotal_Mean</th>\n",
       "      <th>EcogSPTotal_Std</th>\n",
       "      <th>Diagnostics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296113</td>\n",
       "      <td>47.80054</td>\n",
       "      <td>0.159046</td>\n",
       "      <td>2.197026</td>\n",
       "      <td>0.263977</td>\n",
       "      <td>47.914268</td>\n",
       "      <td>0.208483</td>\n",
       "      <td>1.880656</td>\n",
       "      <td>0.203772</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108253</td>\n",
       "      <td>24.03280</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.968750</td>\n",
       "      <td>0.054127</td>\n",
       "      <td>24.032800</td>\n",
       "      <td>0.698710</td>\n",
       "      <td>3.559482</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239357</td>\n",
       "      <td>119.57400</td>\n",
       "      <td>0.159046</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>0.133398</td>\n",
       "      <td>119.574000</td>\n",
       "      <td>0.208483</td>\n",
       "      <td>1.418803</td>\n",
       "      <td>0.143276</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # AGE  PTEDUCAT  PTGENDER_Male  PTETHCAT_Not Hisp/Latino  PTETHCAT_Unknown  \\\n",
       "0   77.8      11.0            1.0                       1.0               0.0   \n",
       "1   88.5       9.0            0.0                       1.0               0.0   \n",
       "2   83.1      14.0            1.0                       1.0               0.0   \n",
       "\n",
       "   PTRACCAT_Asian  PTRACCAT_Black  PTRACCAT_Hawaiian/Other PI  \\\n",
       "0             0.0             1.0                         0.0   \n",
       "1             0.0             0.0                         0.0   \n",
       "2             0.0             0.0                         0.0   \n",
       "\n",
       "   PTRACCAT_More than one  PTRACCAT_Unknown     ...       EcogSPDivatt_Std  \\\n",
       "0                     0.0               0.0     ...               0.296113   \n",
       "1                     0.0               0.0     ...               0.108253   \n",
       "2                     0.0               0.0     ...               0.239357   \n",
       "\n",
       "   EcogSPMem_MaxTime  EcogSPMem_Delta  EcogSPMem_Mean  EcogSPMem_Std  \\\n",
       "0           47.80054         0.159046        2.197026       0.263977   \n",
       "1           24.03280         0.125000        3.968750       0.054127   \n",
       "2          119.57400         0.159046        1.479167       0.133398   \n",
       "\n",
       "   EcogSPTotal_MaxTime  EcogSPTotal_Delta  EcogSPTotal_Mean  EcogSPTotal_Std  \\\n",
       "0            47.914268           0.208483          1.880656         0.203772   \n",
       "1            24.032800           0.698710          3.559482         0.397436   \n",
       "2           119.574000           0.208483          1.418803         0.143276   \n",
       "\n",
       "   Diagnostics  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          0.0  \n",
       "\n",
       "[3 rows x 114 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTGENDER_Male</th>\n",
       "      <th>PTETHCAT_Not Hisp/Latino</th>\n",
       "      <th>PTETHCAT_Unknown</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>PTRACCAT_Unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>EcogSPDivatt_Std</th>\n",
       "      <th>EcogSPMem_MaxTime</th>\n",
       "      <th>EcogSPMem_Delta</th>\n",
       "      <th>EcogSPMem_Mean</th>\n",
       "      <th>EcogSPMem_Std</th>\n",
       "      <th>EcogSPTotal_MaxTime</th>\n",
       "      <th>EcogSPTotal_Delta</th>\n",
       "      <th>EcogSPTotal_Mean</th>\n",
       "      <th>EcogSPTotal_Std</th>\n",
       "      <th>Diagnostics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176777</td>\n",
       "      <td>23.7049</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.176777</td>\n",
       "      <td>23.7049</td>\n",
       "      <td>0.46154</td>\n",
       "      <td>1.442308</td>\n",
       "      <td>0.235265</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644205</td>\n",
       "      <td>36.1311</td>\n",
       "      <td>1.375</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.480885</td>\n",
       "      <td>36.1311</td>\n",
       "      <td>1.97436</td>\n",
       "      <td>3.142672</td>\n",
       "      <td>0.720218</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.2623</td>\n",
       "      <td>0.125</td>\n",
       "      <td>2.125</td>\n",
       "      <td>0.755190</td>\n",
       "      <td>6.2623</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.535795</td>\n",
       "      <td>0.453005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # AGE  PTEDUCAT  PTGENDER_Male  PTETHCAT_Not Hisp/Latino  PTETHCAT_Unknown  \\\n",
       "0   69.3      12.0            0.0                       0.0               0.0   \n",
       "1   69.6      16.0            1.0                       1.0               0.0   \n",
       "2   84.6      16.0            0.0                       1.0               0.0   \n",
       "\n",
       "   PTRACCAT_Asian  PTRACCAT_Black  PTRACCAT_Hawaiian/Other PI  \\\n",
       "0             0.0             0.0                         0.0   \n",
       "1             0.0             0.0                         0.0   \n",
       "2             0.0             0.0                         0.0   \n",
       "\n",
       "   PTRACCAT_More than one  PTRACCAT_Unknown     ...       EcogSPDivatt_Std  \\\n",
       "0                     0.0               0.0     ...               0.176777   \n",
       "1                     0.0               0.0     ...               0.644205   \n",
       "2                     0.0               0.0     ...               0.000000   \n",
       "\n",
       "   EcogSPMem_MaxTime  EcogSPMem_Delta  EcogSPMem_Mean  EcogSPMem_Std  \\\n",
       "0            23.7049            0.250           1.625       0.176777   \n",
       "1            36.1311            1.375           3.500       0.480885   \n",
       "2             6.2623            0.125           2.125       0.755190   \n",
       "\n",
       "   EcogSPTotal_MaxTime  EcogSPTotal_Delta  EcogSPTotal_Mean  EcogSPTotal_Std  \\\n",
       "0              23.7049            0.46154          1.442308         0.235265   \n",
       "1              36.1311            1.97436          3.142672         0.720218   \n",
       "2               6.2623            0.00000          1.535795         0.453005   \n",
       "\n",
       "   Diagnostics  \n",
       "0          0.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "\n",
       "[3 rows x 114 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainTestSplit.traintest_split(0.33)\n",
    "\n",
    "Imputation.imputation('meanmode')\n",
    "\n",
    "# ----------------------------------\n",
    "# Feature Reduction \n",
    "# ----------------------------------\n",
    "\n",
    "# Input and Output files from Feature Reduction for train set\n",
    "InputToFeatureReduction_train     ='ImputedMatrix_train.csv'\n",
    "OutputFromFeatureReduction_train  ='Features_train.csv'\n",
    "InputToFeatureReduction_test      ='ImputedMatrix_test.csv'\n",
    "OutputFromFeatureReduction_test   ='Features_test.csv'\n",
    "\n",
    "\n",
    "# Normalization method\n",
    "NormalizationMethod='MinMax'\n",
    "#NormalizationMethod='MeanStd'\n",
    "\n",
    "# Feature Reduction Method and Settings\n",
    "#FeatureReductionMethod='SVD'; \n",
    "ExplainedVariance=0.99; # For method 'SVD'\n",
    "\n",
    "FeatureReductionMethod= 'none'; \n",
    "APpreference=-50; # Hyperparameter for method 'AffinityPropagation'\n",
    "\n",
    "\n",
    "# Run Feature Reduction\n",
    "FeatureReduction.RunFeatureReduction(InputToFeatureReduction_train,OutputFromFeatureReduction_train,\\\n",
    "                                     InputToFeatureReduction_test,OutputFromFeatureReduction_test,\\\n",
    "                                     NormalizationMethod,FeatureReductionMethod,ExplainedVariance,APpreference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = pd.read_csv('Features_train.csv')\n",
    "d_test = pd.read_csv('Features_test.csv')\n",
    "names = list(d)\n",
    "names = [i.replace(\"'\",\"\").replace(\" \",\"\").replace(\"#\",\"\").replace(\"[\",\"\").replace(\"]\",\"\") for i in names]\n",
    "d.columns = names\n",
    "d_test.columns = names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of features we are using:  \n",
    "    1.Demographics (AGE, PTEDUCAT, PTGENDER, PTETHCAT, PTRACCAT, PTMARRY)  \n",
    "    2.APOE4  \n",
    "    3.Years_bl  \n",
    "    4.Dx_bl  \n",
    "    5.CDRSB   \n",
    "    6.ADAS11  \n",
    "    7.ADAS13  \n",
    "    8.MMSE    \n",
    "    9.RAVLT    \n",
    "    10.FAQ  \n",
    "    11.MOCA  \n",
    "    12.ECogPtTotal  \n",
    "    13.EcogSPTotal \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_to_column = {\n",
    "    1: ['AGE','PTEDUCAT','PTGENDER_Male','PTETHCAT_NotHisp/Latino','PTETHCAT_Unknown','PTRACCAT_Asian','PTRACCAT_Black','PTRACCAT_Hawaiian/OtherPI','PTRACCAT_Morethanone','PTRACCAT_Unknown','PTRACCAT_White','PTMARRY_Married', 'PTMARRY_Nevermarried','PTMARRY_Unknown', 'PTMARRY_Widowed'],\n",
    "    2: ['APOE4'],\n",
    "    3: ['Years_bl'],\n",
    "    #4: ['DX_bl_CN', 'DX_bl_EMCI', 'DX_bl_LMCI', 'DX_bl_SMC'],\n",
    "    4: ['CDRSB_MaxTime', 'CDRSB_Delta', 'CDRSB_Mean', 'CDRSB_Std'],\n",
    "    5: ['ADAS11_MaxTime', 'ADAS11_Delta', 'ADAS11_Mean', 'ADAS11_Std'],\n",
    "    6: ['ADAS13_MaxTime', 'ADAS13_Delta', 'ADAS13_Mean', 'ADAS13_Std'],\n",
    "    7: ['MMSE_MaxTime', 'MMSE_Delta', 'MMSE_Mean', 'MMSE_Std'],\n",
    "    8: ['RAVLT_learning_MaxTime', 'RAVLT_learning_Delta', 'RAVLT_learning_Mean', 'RAVLT_learning_Std', 'RAVLT_forgetting_MaxTime', 'RAVLT_forgetting_Delta', 'RAVLT_forgetting_Mean', 'RAVLT_forgetting_Std', 'RAVLT_perc_forgetting_MaxTime', 'RAVLT_perc_forgetting_Delta', 'RAVLT_perc_forgetting_Mean', 'RAVLT_perc_forgetting_Std', 'RAVLT_immediate_MaxTime', 'RAVLT_immediate_Delta', 'RAVLT_immediate_Mean', 'RAVLT_immediate_Std'],\n",
    "    9: ['FAQ_MaxTime', 'FAQ_Delta', 'FAQ_Mean', 'FAQ_Std'], \n",
    "    10: ['MOCA_MaxTime', 'MOCA_Delta', 'MOCA_Mean', 'MOCA_Std'],\n",
    "    11: ['EcogPtLang_MaxTime', 'EcogPtLang_Delta', 'EcogPtLang_Mean', 'EcogPtLang_Std', 'EcogPtVisspat_MaxTime', 'EcogPtVisspat_Delta', 'EcogPtVisspat_Mean', 'EcogPtVisspat_Std', 'EcogPtPlan_MaxTime', 'EcogPtPlan_Delta', 'EcogPtPlan_Mean', 'EcogPtPlan_Std', 'EcogPtOrgan_MaxTime', 'EcogPtOrgan_Delta', 'EcogPtOrgan_Mean', 'EcogPtOrgan_Std', 'EcogPtDivatt_MaxTime', 'EcogPtDivatt_Delta', 'EcogPtDivatt_Mean', 'EcogPtDivatt_Std', 'EcogPtMem_MaxTime', 'EcogPtMem_Delta', 'EcogPtMem_Mean', 'EcogPtMem_Std', 'EcogPtTotal_MaxTime', 'EcogPtTotal_Delta', 'EcogPtTotal_Mean', 'EcogPtTotal_Std'],\n",
    "    12: ['EcogSPLang_MaxTime', 'EcogSPLang_Delta', 'EcogSPLang_Mean', 'EcogSPLang_Std', 'EcogSPVisspat_MaxTime', 'EcogSPVisspat_Delta', 'EcogSPVisspat_Mean', 'EcogSPVisspat_Std', 'EcogSPPlan_MaxTime', 'EcogSPPlan_Delta', 'EcogSPPlan_Mean', 'EcogSPPlan_Std', 'EcogSPOrgan_MaxTime', 'EcogSPOrgan_Delta', 'EcogSPOrgan_Mean', 'EcogSPOrgan_Std', 'EcogSPDivatt_MaxTime', 'EcogSPDivatt_Delta', 'EcogSPDivatt_Mean', 'EcogSPDivatt_Std', 'EcogSPMem_MaxTime', 'EcogSPMem_Delta', 'EcogSPMem_Mean', 'EcogSPMem_Std', 'EcogSPTotal_MaxTime', 'EcogSPTotal_Delta', 'EcogSPTotal_Mean', 'EcogSPTotal_Std'],\n",
    "}\n",
    "\n",
    "from itertools import combinations\n",
    "n = range(1,len(feature_to_column)+1)\n",
    "output = sum([map(list, combinations(n, i)) for i in range(1,6)], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Models_MetaClassifier_NEW.csv','w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    count = 0\n",
    "    for i in output:\n",
    "        writer.writerow([\"Model \"+str(count)]+i)\n",
    "        count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "final_dataFrame = pd.DataFrame()\n",
    "model_num = 0\n",
    "for model_features in output:\n",
    "    c= [] \n",
    "    for i in model_features:\n",
    "        c =  c + feature_to_column[i]\n",
    "    c = c + ['Diagnostics']\n",
    "\n",
    "    data_train = d[c].as_matrix()\n",
    "    data_test = d_test[c].as_matrix()\n",
    "\n",
    "    training_set_X, test_set_X, training_set_Y, test_set_Y = data_train[:,:-1], data_test[:,:-1], data_train[:,-1], data_test[:,-1]\n",
    "    model = RandomForestClassifier(n_estimators = 1000)\n",
    "\n",
    "    model.fit(training_set_X, training_set_Y)\n",
    "        \n",
    "    y_pred = model.predict(test_set_X)\n",
    "    \n",
    "    final_dataFrame['Model'+str(model_num)] = y_pred\n",
    "    model_num += 1\n",
    "    if model_num % 100 == 0:\n",
    "        print model_num\n",
    "    if model_num % 1000 == 0:\n",
    "        final_dataFrame.to_csv(\"MetaClassifer_Dataset_NEW.csv\", index = False)\n",
    "    \n",
    "\n",
    "final_dataFrame['Diagnostics'] = test_set_Y\n",
    "final_dataFrame.to_csv(\"MetaClassifer_Dataset_NEW.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947368421053\n",
      "0.95652173913\n"
     ]
    }
   ],
   "source": [
    "## Look at Results using RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "d_meta = pd.read_csv('MetaClassifier_Dataset.csv')\n",
    "labels = list(d_meta)\n",
    "\n",
    "data = d_meta.as_matrix()[:,:] \n",
    "\n",
    "Y = data[:, -1]\n",
    "X = data[:,0:-1]\n",
    "\n",
    "training_set_X, test_set_X, training_set_Y, test_set_Y, = train_test_split(\n",
    "X, Y, test_size=0.33)\n",
    "\n",
    "##### Save files #####\n",
    "Yy = np.transpose(np.asmatrix(training_set_Y))\n",
    "Yyy = np.transpose(np.asmatrix(test_set_Y))\n",
    "\n",
    "train = np.concatenate((training_set_X, Yy), axis=1)\n",
    "test = np.concatenate((test_set_X, Yyy), axis=1)\n",
    "\n",
    "data_train = pd.DataFrame(data=train[:,:],  \n",
    "             columns=labels)  \n",
    "\n",
    "data_test = pd.DataFrame(data=test[:,:],  \n",
    "             columns=labels) \n",
    "\n",
    "data_train = data_train.as_matrix()\n",
    "data_test = data_test.as_matrix()\n",
    "\n",
    "training_set_X, test_set_X, training_set_Y, test_set_Y = data_train[:,:-1], data_test[:,:-1], data_train[:,-1], data_test[:,-1]\n",
    "model = RandomForestClassifier(n_estimators = 2000)\n",
    "\n",
    "model.fit(training_set_X, training_set_Y)\n",
    "\n",
    "y_pred = model.predict(test_set_X)\n",
    "\n",
    "count = []\n",
    "recall = []\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == test_set_Y[i]:\n",
    "        count.append(1)\n",
    "    else:\n",
    "        count.append(0)\n",
    "        \n",
    "    if test_set_Y[i] == 1:\n",
    "        if y_pred[i] == 1:\n",
    "            recall.append(1)\n",
    "        else:\n",
    "            recall.append(0)\n",
    "        \n",
    "print sum(count)/float(len(count))\n",
    "print sum(recall)/float(len(recall))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
