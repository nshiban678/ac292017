{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David Castineira\\Anaconda2\\lib\\site-packages\\pandas\\computation\\__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "#                                            STEP 1: Import libraries\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "#%reset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "import matplotlib as mpl\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sys import stdout\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "from operator import itemgetter\n",
    "from numpy import genfromtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "#                                            STEP 2: Define functions\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def load_numerical_table(fileName):\n",
    "    \"\"\"Function to load .csv file that has numerical-only data; it also displays some basic info about the .csv file content\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    -fileName: path of rthe .csv file we want to load; put file name only if file is located in current path\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    InputMatrix  = numpy array with all values, equivalent to the values in the input .csv file (but no headers)\n",
    "    InputHeaders = list with headers in input .csv file\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Load .csv file into panda dataframe and show head\n",
    "    # ----------------------------------------------------\n",
    "    transformed_data = pd.read_csv(fileName)\n",
    "    display(transformed_data.head(3))\n",
    "\n",
    "    # Put headers into list\n",
    "    # ----------------------\n",
    "    InputHeaders=list(transformed_data)\n",
    "\n",
    "\n",
    "    # Turn data frames into matrix\n",
    "    # ---------------------------------\n",
    "    InputMatrix  = transformed_data.as_matrix(); InputMatrix = np.array(InputMatrix) ;\n",
    "    #print \"Input Matrix Size:\"; print \"-----------------------\"\n",
    "    #print InputMatrix.shape\n",
    "\n",
    "    # Turn -1000 into NaNs\n",
    "    # ---------------------------------\n",
    "    #InputMatrix[InputMatrix==-1000] = np.nan\n",
    "    \n",
    "    return InputMatrix,InputHeaders\n",
    "\n",
    "def NormalizeDataPatients(InputMatrix_train,NormalizationMethod):\n",
    "    \"\"\"Function to normalize all columns in a matrix according to NormalizationMethod (see below)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    -InputMatrix: Matrix we want to normalize\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    NormalizationMethod: 'MeanStd' or 'MinMax' for now.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # OPTION 1: Mean and Std\n",
    "    # -----------------------\n",
    "    # Transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features \n",
    "    # by their standard deviation.Scaled data wil have zero mean and unit variance\n",
    "    if NormalizationMethod=='MeanStd':\n",
    "        #X= preprocessing.scale(InputMatrix_train)\n",
    "        normMap=preprocessing.StandardScaler().fit(InputMatrix_train)\n",
    "        X_train=normMap.transform(InputMatrix_train) \n",
    "        #X_test=normMap.transform(InputMatrix_test) \n",
    "        \n",
    "\n",
    "    # OPTION 2: Min and Max\n",
    "    # ----------------------\n",
    "    # Scaling features to lie between a given minimum and maximum value, often between zero and one, or so that the maximum absolute \n",
    "    # value of each feature is scaled to unit size.\n",
    "    if NormalizationMethod=='MinMax':\n",
    "        \n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        normMap=min_max_scaler.fit(InputMatrix_train)\n",
    "        X_train = min_max_scaler.fit_transform(InputMatrix_train,normMap)\n",
    "        #X_test = min_max_scaler.fit_transform(InputMatrix_test,normMap)      \n",
    "\n",
    "    return X_train\n",
    "\n",
    "\n",
    "def NormalizeData(InputMatrix_train,InputMatrix_test,NormalizationMethod):\n",
    "    \"\"\"Function to normalize all columns in a matrix according to NormalizationMethod (see below)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    -InputMatrix: Matrix we want to normalize\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    NormalizationMethod: 'MeanStd' or 'MinMax' for now.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # OPTION 1: Mean and Std\n",
    "    # -----------------------\n",
    "    # Transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features \n",
    "    # by their standard deviation.Scaled data wil have zero mean and unit variance\n",
    "    if NormalizationMethod=='MeanStd':\n",
    "        #X= preprocessing.scale(InputMatrix_train)\n",
    "        normMap=preprocessing.StandardScaler().fit(InputMatrix_train)\n",
    "        X_train=normMap.transform(InputMatrix_train) \n",
    "        X_test=normMap.transform(InputMatrix_test) \n",
    "        \n",
    "\n",
    "    # OPTION 2: Min and Max\n",
    "    # ----------------------\n",
    "    # Scaling features to lie between a given minimum and maximum value, often between zero and one, or so that the maximum absolute \n",
    "    # value of each feature is scaled to unit size.\n",
    "    if NormalizationMethod=='MinMax':\n",
    "        \n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        normMap=min_max_scaler.fit(InputMatrix_train)\n",
    "        X_train = min_max_scaler.fit_transform(InputMatrix_train,normMap)\n",
    "        X_test = min_max_scaler.fit_transform(InputMatrix_test,normMap)      \n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def clustering_Patients(X,XHeaders,FeatureReductionMethod,APpreference):\n",
    "        \n",
    "    if ClusteringMethod=='AffinityPropagation':\n",
    "\n",
    "        # --------------------------------------\n",
    "        # OPTION 2: Affinity Propagation\n",
    "        # --------------------------------------\n",
    "\n",
    "        # Affinity Propagation is a clustering technique that identifies \"exemplars\" (which will be our reduced features)\n",
    "\n",
    "        # References:\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation.fit\n",
    "      \n",
    "\n",
    "        print \" Feature reduction implementing using Affinity Propagation \"\n",
    "        print \"----------------------------------------------------------------------------\"\n",
    "        \n",
    "        # Apply Affinity Propagation to matrix X.T\n",
    "        af = AffinityPropagation(preference=APpreference).fit(X.T)\n",
    "        \n",
    "        \n",
    "        # Identify indices for examplars (i.e., features that are cluster centers)\n",
    "        cluster_centers_indices = af.cluster_centers_indices_\n",
    "        \n",
    "        # Reduce train set\n",
    "        HeadersReduced = [XHeaders[i] for i in cluster_centers_indices]\n",
    "        Xreduced=X[:,cluster_centers_indices]\n",
    "        \n",
    "        \n",
    "        #print \"Selected features:\"\n",
    "        #print cluster_centers_indices\n",
    "        #print HeadersReduced\n",
    "\n",
    "        # Identify labels for each feature (i.e., to which cluster center they are linked)\n",
    "        # ---------------------------------------------------------------------------------\n",
    "        labels = af.labels_\n",
    "        #print labels\n",
    "        #print 'Affinity Propagation finished'\n",
    "        print \"- Original train matrix has size \" + str(X.shape)\n",
    "        print \"- Reduced train matrix has size \" + str(Xreduced.shape)\n",
    "        print \"- Number of rows selected \" + str(len(HeadersReduced))\n",
    "\n",
    "\n",
    "    return Xreduced,HeadersReduced,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># RID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTGENDER_Male</th>\n",
       "      <th>PTETHCAT_Not Hisp/Latino</th>\n",
       "      <th>PTETHCAT_Unknown</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>...</th>\n",
       "      <th>EcogSPDivatt_Std</th>\n",
       "      <th>EcogSPMem_MaxTime</th>\n",
       "      <th>EcogSPMem_Delta</th>\n",
       "      <th>EcogSPMem_Mean</th>\n",
       "      <th>EcogSPMem_Std</th>\n",
       "      <th>EcogSPTotal_MaxTime</th>\n",
       "      <th>EcogSPTotal_Delta</th>\n",
       "      <th>EcogSPTotal_Mean</th>\n",
       "      <th>EcogSPTotal_Std</th>\n",
       "      <th>Diagnostics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1240.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296342</td>\n",
       "      <td>0.038037</td>\n",
       "      <td>0.16111</td>\n",
       "      <td>2.252046</td>\n",
       "      <td>0.262939</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>1.930516</td>\n",
       "      <td>0.208592</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4823.0</td>\n",
       "      <td>82.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.87500</td>\n",
       "      <td>2.028572</td>\n",
       "      <td>1.184218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.657212</td>\n",
       "      <td>0.801365</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1379.0</td>\n",
       "      <td>87.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296342</td>\n",
       "      <td>0.038037</td>\n",
       "      <td>0.16111</td>\n",
       "      <td>2.252046</td>\n",
       "      <td>0.262939</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>1.930516</td>\n",
       "      <td>0.208592</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    # RID   AGE  PTEDUCAT  PTGENDER_Male  PTETHCAT_Not Hisp/Latino  \\\n",
       "0  1240.0  67.0      16.0            0.0                       1.0   \n",
       "1  4823.0  82.2      18.0            1.0                       1.0   \n",
       "2  1379.0  87.7       8.0            1.0                       1.0   \n",
       "\n",
       "   PTETHCAT_Unknown  PTRACCAT_Asian  PTRACCAT_Black  \\\n",
       "0               0.0             0.0             0.0   \n",
       "1               0.0             0.0             0.0   \n",
       "2               0.0             0.0             0.0   \n",
       "\n",
       "   PTRACCAT_Hawaiian/Other PI  PTRACCAT_More than one     ...       \\\n",
       "0                         0.0                     0.0     ...        \n",
       "1                         0.0                     0.0     ...        \n",
       "2                         0.0                     0.0     ...        \n",
       "\n",
       "   EcogSPDivatt_Std  EcogSPMem_MaxTime  EcogSPMem_Delta  EcogSPMem_Mean  \\\n",
       "0          0.296342           0.038037          0.16111        2.252046   \n",
       "1          0.974279           0.000000          2.87500        2.028572   \n",
       "2          0.296342           0.038037          0.16111        2.252046   \n",
       "\n",
       "   EcogSPMem_Std  EcogSPTotal_MaxTime  EcogSPTotal_Delta  EcogSPTotal_Mean  \\\n",
       "0       0.262939             0.036855           0.226158          1.930516   \n",
       "1       1.184218             0.000000           2.000000          1.657212   \n",
       "2       0.262939             0.036855           0.226158          1.930516   \n",
       "\n",
       "   EcogSPTotal_Std  Diagnostics  \n",
       "0         0.208592          1.0  \n",
       "1         0.801365          1.0  \n",
       "2         0.208592          1.0  \n",
       "\n",
       "[3 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># RID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTGENDER_Male</th>\n",
       "      <th>PTETHCAT_Not Hisp/Latino</th>\n",
       "      <th>PTETHCAT_Unknown</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>...</th>\n",
       "      <th>EcogSPDivatt_Std</th>\n",
       "      <th>EcogSPMem_MaxTime</th>\n",
       "      <th>EcogSPMem_Delta</th>\n",
       "      <th>EcogSPMem_Mean</th>\n",
       "      <th>EcogSPMem_Std</th>\n",
       "      <th>EcogSPTotal_MaxTime</th>\n",
       "      <th>EcogSPTotal_Delta</th>\n",
       "      <th>EcogSPTotal_Mean</th>\n",
       "      <th>EcogSPTotal_Std</th>\n",
       "      <th>Diagnostics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1118.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16111</td>\n",
       "      <td>2.285715</td>\n",
       "      <td>0.201635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>2.714730</td>\n",
       "      <td>0.304656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>712.0</td>\n",
       "      <td>76.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296342</td>\n",
       "      <td>0.038037</td>\n",
       "      <td>0.16111</td>\n",
       "      <td>2.252046</td>\n",
       "      <td>0.262939</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>1.930516</td>\n",
       "      <td>0.208592</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328.0</td>\n",
       "      <td>76.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296342</td>\n",
       "      <td>0.038037</td>\n",
       "      <td>0.16111</td>\n",
       "      <td>2.252046</td>\n",
       "      <td>0.262939</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>1.930516</td>\n",
       "      <td>0.208592</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    # RID   AGE  PTEDUCAT  PTGENDER_Male  PTETHCAT_Not Hisp/Latino  \\\n",
       "0  1118.0  82.5      12.0            1.0                       1.0   \n",
       "1   712.0  76.6      16.0            1.0                       1.0   \n",
       "2   328.0  76.6      17.0            1.0                       1.0   \n",
       "\n",
       "   PTETHCAT_Unknown  PTRACCAT_Asian  PTRACCAT_Black  \\\n",
       "0               0.0             0.0             0.0   \n",
       "1               0.0             0.0             0.0   \n",
       "2               0.0             0.0             0.0   \n",
       "\n",
       "   PTRACCAT_Hawaiian/Other PI  PTRACCAT_More than one     ...       \\\n",
       "0                         0.0                     0.0     ...        \n",
       "1                         0.0                     0.0     ...        \n",
       "2                         0.0                     0.0     ...        \n",
       "\n",
       "   EcogSPDivatt_Std  EcogSPMem_MaxTime  EcogSPMem_Delta  EcogSPMem_Mean  \\\n",
       "0          0.409840           0.000000          0.16111        2.285715   \n",
       "1          0.296342           0.038037          0.16111        2.252046   \n",
       "2          0.296342           0.038037          0.16111        2.252046   \n",
       "\n",
       "   EcogSPMem_Std  EcogSPTotal_MaxTime  EcogSPTotal_Delta  EcogSPTotal_Mean  \\\n",
       "0       0.201635             0.000000           0.226158          2.714730   \n",
       "1       0.262939             0.036855           0.226158          1.930516   \n",
       "2       0.262939             0.036855           0.226158          1.930516   \n",
       "\n",
       "   EcogSPTotal_Std  Diagnostics  \n",
       "0         0.304656          0.0  \n",
       "1         0.208592          1.0  \n",
       "2         0.208592          1.0  \n",
       "\n",
       "[3 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature reduction implementing using Affinity Propagation \n",
      "----------------------------------------------------------------------------\n",
      "- Original train matrix has size (119L, 1737L)\n",
      "- Reduced train matrix has size (119L, 11L)\n",
      "- Number of rows selected 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "#                                            STEP 3: Cluster patients\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ClusteringMethod      = 'AffinityPropagation'\n",
    "NormalizationMethod   = 'MinMax'\n",
    "APpreference          = -20\n",
    "ClusterAnalysisThresh = 0.8\n",
    "\n",
    "\n",
    "# Load train and test data from .csv numerical-only table and concatenate\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "Xpatients_train,XHeaders  = load_numerical_table('ImputedMatrix_train.csv')\n",
    "Xpatients_test, XHeaders  = load_numerical_table('ImputedMatrix_test.csv')\n",
    "Xpatients                 = np.concatenate((Xpatients_train, Xpatients_test), axis=0)\n",
    "\n",
    "\n",
    "# Remove Diagnostics from clustering\n",
    "# -----------------------------------\n",
    "XDiagnosis      = Xpatients[:,-1]\n",
    "Xpatients       = np.delete(Xpatients,-1,axis=1)\n",
    "XHeaders        = np.delete(XHeaders,-1,axis=0)\n",
    "\n",
    "\n",
    "# Remove RID for clustering patients (it is a misleading feature for this)\n",
    "# -------------------------------------------------------------------------\n",
    "if XHeaders[0].find('RID')!=-1: \n",
    "    XHeaders              = np.delete(XHeaders,0,axis=0)\n",
    "    XpatientHeaders       = map(str, Xpatients[:,0] )\n",
    "    Xpatients             = np.delete(Xpatients, (0), axis=1)\n",
    "else:\n",
    "    XpatientHeaders       = map(str,range(Xpatients[0,:].size))    \n",
    "\n",
    "    \n",
    "# Transpose matrix (so we can cluster on patients rather than features)\n",
    "# ----------------------------------------------------------------------\n",
    "XpatientsT=Xpatients.T\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "XpatientsNormT=NormalizeDataPatients(XpatientsT,NormalizationMethod)\n",
    "\n",
    "   \n",
    "# Clustering\n",
    "# ------------------------\n",
    "XpatientsReduced,XpatientHeadersReduced,Patientlabels=clustering_Patients(XpatientsNormT,XpatientHeaders,ClusteringMethod,APpreference)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       -----------------------------------------\n",
      "                            CLUSTER ANALYSIS for PATIENTS\n",
      "                       -----------------------------------------\n",
      "  \n",
      "Cluster0 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  122\n",
      "   - Number of patients in this cluster with true AD:  12 (= 9.84 %)\n",
      "   - Number of patients in this cluster that were missclasified:  1 (= 0.82 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTRACCAT_Hawaiian/Other PI' 'PTMARRY_Unknown' 'DX_bl_SMC'\n",
      " 'RAVLT_forgetting_Delta' 'EcogPtLang_Delta']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTRACCAT_Unknown' 'CDRSB_MaxTime' 'ADAS11_MaxTime' 'ADAS11_Delta'\n",
      " 'ADAS13_MaxTime' 'ADAS13_Delta' 'MMSE_MaxTime' 'RAVLT_learning_MaxTime'\n",
      " 'RAVLT_learning_Delta' 'RAVLT_forgetting_MaxTime'\n",
      " 'RAVLT_perc_forgetting_MaxTime' 'RAVLT_perc_forgetting_Delta'\n",
      " 'RAVLT_immediate_MaxTime' 'RAVLT_immediate_Delta' 'FAQ_MaxTime']\n",
      "  \n",
      "Cluster1 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  176\n",
      "   - Number of patients in this cluster with true AD:  11 (= 6.25 %)\n",
      "   - Number of patients in this cluster that were missclasified:  4 (= 2.27 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTRACCAT_Hawaiian/Other PI' 'PTMARRY_Never married' 'CDRSB_MaxTime'\n",
      " 'FAQ_MaxTime' 'EcogPtLang_Delta' 'EcogPtTotal_Delta']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTETHCAT_Unknown' 'PTRACCAT_Unknown' 'PTMARRY_Unknown' 'ADAS11_MaxTime'\n",
      " 'ADAS11_Delta' 'ADAS13_MaxTime' 'MMSE_Delta' 'RAVLT_learning_Delta'\n",
      " 'RAVLT_forgetting_Delta' 'RAVLT_immediate_Delta' 'EcogPtMem_Delta']\n",
      "  \n",
      "Cluster2 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  114\n",
      "   - Number of patients in this cluster with true AD:  15 (= 13.16 %)\n",
      "   - Number of patients in this cluster that were missclasified:  3 (= 2.63 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTETHCAT_Unknown' 'PTRACCAT_More than one' 'PTMARRY_Unknown' 'DX_bl_SMC'\n",
      " 'RAVLT_forgetting_Delta']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTRACCAT_Hawaiian/Other PI' 'PTRACCAT_Unknown' 'ADAS11_MaxTime'\n",
      " 'ADAS13_MaxTime' 'RAVLT_perc_forgetting_Delta' 'RAVLT_immediate_Delta'\n",
      " 'MOCA_Delta' 'EcogPtLang_Delta' 'EcogPtVisspat_Delta' 'EcogPtTotal_Delta']\n",
      "  \n",
      "Cluster3 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  148\n",
      "   - Number of patients in this cluster with true AD:  3 (= 2.03 %)\n",
      "   - Number of patients in this cluster that were missclasified:  0 (= 0.0 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTRACCAT_Unknown' 'DX_bl_CN' 'DX_bl_SMC']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTETHCAT_Unknown' 'PTRACCAT_Hawaiian/Other PI' 'CDRSB_Delta' 'CDRSB_Mean'\n",
      " 'ADAS11_MaxTime' 'ADAS11_Delta' 'ADAS13_MaxTime' 'ADAS13_Delta'\n",
      " 'MMSE_Delta' 'RAVLT_forgetting_Delta' 'RAVLT_immediate_Delta' 'FAQ_Delta'\n",
      " 'FAQ_Mean' 'FAQ_Std' 'MOCA_Delta' 'EcogPtLang_Delta' 'EcogPtVisspat_Delta'\n",
      " 'EcogPtTotal_Delta' 'EcogSPPlan_Delta']\n",
      "  \n",
      "Cluster4 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  155\n",
      "   - Number of patients in this cluster with true AD:  114 (= 73.55 %)\n",
      "   - Number of patients in this cluster that were missclasified:  4 (= 2.58 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['CDRSB_Delta' 'CDRSB_Mean' 'CDRSB_Std' 'ADAS11_Delta' 'ADAS11_Std'\n",
      " 'ADAS13_Delta' 'ADAS13_Std' 'MMSE_Delta' 'MMSE_Std' 'RAVLT_learning_Delta'\n",
      " 'RAVLT_forgetting_Delta' 'RAVLT_perc_forgetting_Delta'\n",
      " 'RAVLT_immediate_Delta' 'FAQ_Delta' 'FAQ_Mean' 'FAQ_Std' 'MOCA_Delta'\n",
      " 'EcogPtLang_Delta' 'EcogPtVisspat_MaxTime' 'EcogPtVisspat_Delta'\n",
      " 'EcogPtDivatt_MaxTime' 'EcogPtMem_Delta' 'EcogSPLang_Delta'\n",
      " 'EcogSPVisspat_Delta' 'EcogSPPlan_Delta' 'EcogSPMem_Delta'\n",
      " 'EcogSPTotal_Delta']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTETHCAT_Unknown' 'PTRACCAT_Hawaiian/Other PI' 'PTRACCAT_More than one'\n",
      " 'PTRACCAT_Unknown' 'PTMARRY_Never married' 'ADAS11_MaxTime'\n",
      " 'ADAS13_MaxTime']\n",
      "  \n",
      "Cluster5 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  314\n",
      "   - Number of patients in this cluster with true AD:  229 (= 72.93 %)\n",
      "   - Number of patients in this cluster that were missclasified:  13 (= 4.14 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['ADAS11_MaxTime' 'ADAS13_MaxTime' 'FAQ_Mean']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTETHCAT_Unknown' 'PTRACCAT_Hawaiian/Other PI' 'PTRACCAT_Unknown'\n",
      " 'PTMARRY_Unknown' 'ORIGPROT_ADNIGO' 'DX_bl_CN' 'DX_bl_SMC'\n",
      " 'RAVLT_forgetting_Delta']\n",
      "  \n",
      "Cluster6 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  78\n",
      "   - Number of patients in this cluster with true AD:  49 (= 62.82 %)\n",
      "   - Number of patients in this cluster that were missclasified:  5 (= 6.41 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTETHCAT_Unknown' 'CDRSB_MaxTime' 'CDRSB_Delta' 'CDRSB_Std'\n",
      " 'ADAS11_Delta' 'ADAS11_Std' 'ADAS13_Delta' 'ADAS13_Std' 'MMSE_MaxTime'\n",
      " 'MMSE_Delta' 'MMSE_Std' 'RAVLT_learning_MaxTime' 'RAVLT_learning_Delta'\n",
      " 'RAVLT_forgetting_MaxTime' 'RAVLT_perc_forgetting_MaxTime'\n",
      " 'RAVLT_perc_forgetting_Delta' 'RAVLT_perc_forgetting_Std'\n",
      " 'RAVLT_immediate_MaxTime' 'RAVLT_immediate_Delta' 'RAVLT_immediate_Std'\n",
      " 'FAQ_MaxTime' 'FAQ_Delta' 'FAQ_Std' 'MOCA_MaxTime' 'MOCA_Delta'\n",
      " 'EcogPtLang_MaxTime' 'EcogPtLang_Delta' 'EcogPtVisspat_MaxTime'\n",
      " 'EcogPtVisspat_Delta' 'EcogPtPlan_MaxTime' 'EcogPtDivatt_Delta'\n",
      " 'EcogPtMem_MaxTime' 'EcogPtTotal_MaxTime' 'EcogPtTotal_Delta'\n",
      " 'EcogSPLang_MaxTime' 'EcogSPVisspat_MaxTime' 'EcogSPVisspat_Delta'\n",
      " 'EcogSPPlan_MaxTime' 'EcogSPOrgan_MaxTime' 'EcogSPOrgan_Delta'\n",
      " 'EcogSPMem_MaxTime' 'EcogSPMem_Delta' 'EcogSPTotal_MaxTime'\n",
      " 'EcogSPTotal_Delta']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTRACCAT_Asian' 'PTRACCAT_Hawaiian/Other PI' 'PTRACCAT_More than one'\n",
      " 'PTRACCAT_Unknown' 'PTMARRY_Never married' 'PTMARRY_Unknown'\n",
      " 'ADAS11_MaxTime' 'ADAS13_MaxTime' 'RAVLT_forgetting_Delta'\n",
      " 'EcogPtMem_Delta']\n",
      "  \n",
      "Cluster7 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  42\n",
      "   - Number of patients in this cluster with true AD:  3 (= 7.14 %)\n",
      "   - Number of patients in this cluster that were missclasified:  2 (= 4.76 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTRACCAT_Black' 'Years_bl' 'ORIGPROT_ADNIGO' 'DX_bl_SMC'\n",
      " 'RAVLT_forgetting_Delta' 'RAVLT_forgetting_Std'\n",
      " 'RAVLT_perc_forgetting_Std' 'EcogPtMem_Delta']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTETHCAT_Unknown' 'PTRACCAT_Hawaiian/Other PI' 'PTRACCAT_More than one'\n",
      " 'PTRACCAT_Unknown' 'PTMARRY_Unknown' 'CDRSB_Delta' 'ADAS11_MaxTime'\n",
      " 'ADAS11_Delta' 'ADAS13_MaxTime' 'ADAS13_Delta'\n",
      " 'RAVLT_perc_forgetting_Delta' 'RAVLT_immediate_Delta' 'MOCA_Delta'\n",
      " 'EcogPtLang_Delta' 'EcogPtVisspat_Delta' 'EcogPtPlan_Delta'\n",
      " 'EcogPtOrgan_Delta' 'EcogPtTotal_Delta']\n",
      "  \n",
      "Cluster8 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  154\n",
      "   - Number of patients in this cluster with true AD:  9 (= 5.84 %)\n",
      "   - Number of patients in this cluster that were missclasified:  0 (= 0.0 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTRACCAT_More than one' 'PTRACCAT_Unknown' 'DX_bl_CN'\n",
      " 'RAVLT_forgetting_Delta']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTRACCAT_Hawaiian/Other PI' 'PTMARRY_Unknown' 'CDRSB_Delta'\n",
      " 'ADAS11_MaxTime' 'ADAS11_Delta' 'ADAS13_MaxTime' 'ADAS13_Delta'\n",
      " 'MMSE_Delta' 'RAVLT_perc_forgetting_Delta' 'MOCA_Delta' 'EcogPtLang_Delta'\n",
      " 'EcogPtPlan_Delta']\n",
      "  \n",
      "Cluster9 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  141\n",
      "   - Number of patients in this cluster with true AD:  24 (= 17.02 %)\n",
      "   - Number of patients in this cluster that were missclasified:  5 (= 3.55 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTRACCAT_Unknown' 'PTMARRY_Never married' 'PTMARRY_Unknown'\n",
      " 'ORIGPROT_ADNIGO' 'RAVLT_perc_forgetting_Delta'\n",
      " 'RAVLT_perc_forgetting_Std']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTRACCAT_Hawaiian/Other PI' 'PTRACCAT_More than one' 'ADAS11_MaxTime'\n",
      " 'ADAS13_MaxTime' 'RAVLT_forgetting_Delta' 'EcogPtLang_Delta'\n",
      " 'EcogPtOrgan_Delta' 'EcogPtTotal_Delta']\n",
      "  \n",
      "Cluster10 :\n",
      "--------------------------------------------------\n",
      "   - Number of patients in this cluster:  293\n",
      "   - Number of patients in this cluster with true AD:  205 (= 69.97 %)\n",
      "   - Number of patients in this cluster that were missclasified:  18 (= 6.14 %)\n",
      " \n",
      "   - Features much higher than population mean:  ['PTETHCAT_Unknown' 'MMSE_Delta' 'RAVLT_forgetting_Delta' 'FAQ_Mean'\n",
      " 'MOCA_Delta']\n",
      " \n",
      "   - Features much lower than population mean:  ['PTRACCAT_Hawaiian/Other PI' 'PTRACCAT_Unknown' 'DX_bl_CN' 'DX_bl_SMC'\n",
      " 'ADAS11_MaxTime' 'ADAS13_MaxTime']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "#                                STEP 4: Analyze patient clustering results\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "print \"                       -----------------------------------------\";\n",
    "print \"                            CLUSTER ANALYSIS for PATIENTS\"; \n",
    "print \"                       -----------------------------------------\"\n",
    "\n",
    "\n",
    "# Initialize\n",
    "# ------------------\n",
    "Cluster_MEAN       = np.array([]);\n",
    "Cluster_MEAN_Ratio = np.array([]);\n",
    "populationMean     = np.mean(Xpatients, axis=0);\n",
    "\n",
    "\n",
    "# Identify indexes for missclasified patients in file results.csv (test set)\n",
    "# --------------------------------------------------------------------------\n",
    "results_data    = genfromtxt('results.csv', delimiter=',')\n",
    "missPatients    = np.nonzero(np.absolute(results_data[:,0]) -np.absolute(results_data[:,1]) !=0)\n",
    "missPatients    = np.asarray(missPatients,dtype=int)\n",
    "missPatients    = missPatients.flatten()\n",
    "missPatientsALL = missPatients+Xpatients_train.shape[0]\n",
    "\n",
    "\n",
    "# Loop over each cluster\n",
    "# -------------------------------------------------------------------------\n",
    "for i in range(max(Patientlabels)+1):\n",
    "    \n",
    "    # Display basic info for this cluster\n",
    "    print \"  \"; print \"Cluster\"+str(i),\":\"; print \"--------------------------------------------------\"; \n",
    "    \n",
    "    \n",
    "    # Patient indexes for this cluster\n",
    "    inds    =  np.nonzero(Patientlabels==i)\n",
    "    inds    =  np.asarray(inds,dtype=int)\n",
    "    inds    =  inds.flatten()\n",
    "    print \"   - Number of patients in this cluster: \", + inds.size\n",
    "   \n",
    "    # Number of patients with AD in this cluster\n",
    "    indsAD=itemgetter(*inds)(XDiagnosis);\n",
    "    indsAD=np.asarray(indsAD)\n",
    "    print \"   - Number of patients in this cluster with true AD: \",+ np.count_nonzero(indsAD),\\\n",
    "    \"(=\",+np.around(np.true_divide(np.count_nonzero(indsAD),inds.size)*100,decimals=2),\"%)\"\n",
    "\n",
    "    \n",
    "    # Number of patients that were missclasified\n",
    "    indsMISS = np.intersect1d(inds,missPatientsALL)\n",
    "    indsMISS = np.asarray(indsMISS)\n",
    "    print \"   - Number of patients in this cluster that were missclasified: \",+ indsMISS.shape[0],\\\n",
    "    \"(=\",+np.around(np.true_divide(indsMISS.shape[0],inds.size)*100,decimals=2),\"%)\"\n",
    "\n",
    "    inds    =  inds.flatten()\n",
    "    \n",
    "    # Patient RIDs\n",
    "    indsRID=itemgetter(*inds)(XpatientHeaders)\n",
    "    #print \"   - Patient RIDs for this cluster: \",\n",
    "    #print np.asarray(indsRID)\n",
    "    \n",
    "    # Mean of features for this particular cluster\n",
    "    clustermean        = np.mean(Xpatients[inds,:], axis=0);\n",
    "    Cluster_MEAN       = np.vstack([Cluster_MEAN, clustermean]) if Cluster_MEAN.size else clustermean\n",
    "    \n",
    "     # Ratio of (mean of features for this particular cluster) to (mean of features for whole population)\n",
    "    clustermeanRatio   = np.divide(clustermean, populationMean)\n",
    "    Cluster_MEAN_Ratio = np.vstack([Cluster_MEAN_Ratio, clustermeanRatio]) if Cluster_MEAN_Ratio.size else clustermeanRatio\n",
    "    \n",
    "    # Identify features above the population mean\n",
    "    print \" \"; print \"   - Features much higher than population mean: \", \n",
    "    clusterAbove    =  np.nonzero(clustermeanRatio>=(1+ClusterAnalysisThresh));\n",
    "    clusterAbove    =  np.asarray(clusterAbove,dtype=int);\n",
    "    clusterAbove   =   clusterAbove.flatten()\n",
    "    print XHeaders[clusterAbove];\n",
    "    \n",
    "    # Identify features below the population mean\n",
    "    print \" \"; print \"   - Features much lower than population mean: \", \n",
    "    clusterBelow    =  np.nonzero(clustermeanRatio<=(1-ClusterAnalysisThresh));\n",
    "    clusterBelow    =  np.asarray(clusterBelow,dtype=int);\n",
    "    clusterBelow   =   clusterBelow.flatten()\n",
    "    print XHeaders[clusterBelow]\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
