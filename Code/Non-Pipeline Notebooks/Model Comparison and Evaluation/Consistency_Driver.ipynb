{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/courtneycochrane/anaconda/envs/py27/lib/python2.7/site-packages/nbformat/current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import current\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = current.read(f, 'json')\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "            for cell in nb.worksheets[0].cells:\n",
    "                if cell.cell_type == 'code' and cell.language == 'python':\n",
    "                    # transform the input to executable Python\n",
    "                    code = self.shell.input_transformer_manager.transform_cell(cell.input)\n",
    "                    # run the code in themodule\n",
    "                    exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from MergeDiagnosis_AdjustedLabels.ipynb\n",
      "importing Jupyter notebook from LongitudinalDataAnalysis.ipynb\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Categorical_Updated.ipynb\n",
      "importing Jupyter notebook from Imputation.ipynb\n",
      "importing Jupyter notebook from FeatureReduction.ipynb\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from SupervisedLearning.ipynb\n",
      "importing Jupyter notebook from ModelPerformance.ipynb\n",
      "importing Jupyter notebook from TrainTestSplit.ipynb\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy\n",
    "import pandas\n",
    "import csv\n",
    "import MergeDiagnosis_AdjustedLabels\n",
    "import LongitudinalDataAnalysis\n",
    "import Categorical_Updated\n",
    "import Imputation\n",
    "import FeatureReduction\n",
    "import SupervisedLearning\n",
    "import ModelPerformance\n",
    "import TrainTestSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Merge Data\n",
    "# -------------------------------\n",
    "merged_data = MergeDiagnosis_AdjustedLabels.data_preprocess(study = \"all\",imaging_to_drop = 'all', reversions = 'label0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columsn that are one-hot encoded\n",
      "-------------------------------------\n",
      "['VISCODE', 'COLPROT', 'ORIGPROT', 'DX_bl', 'PTGENDER', 'PTETHCAT', 'PTRACCAT', 'PTMARRY']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Categorical to Numerical\n",
    "# -------------------------------\n",
    "date_cols = ['update_stamp','EXAMDATE','EXAMDATE_bl']\n",
    "cols_to_ignore = ['PTID']\n",
    "\n",
    "Categorical_Updated.categorical_conversion(date_cols,cols_to_ignore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RID</th>\n",
       "      <th>SITE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>CDRSB</th>\n",
       "      <th>ADAS11</th>\n",
       "      <th>ADAS13</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>...</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>PTRACCAT_Unknown</th>\n",
       "      <th>PTRACCAT_White</th>\n",
       "      <th>PTMARRY_Married</th>\n",
       "      <th>PTMARRY_Never married</th>\n",
       "      <th>PTMARRY_Unknown</th>\n",
       "      <th>PTMARRY_Widowed</th>\n",
       "      <th>AD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>74.3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.67</td>\n",
       "      <td>18.67</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>81.3</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>22.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>81.3</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  RID  SITE   AGE  PTEDUCAT  APOE4  CDRSB  ADAS11  ADAS13  MMSE  \\\n",
       "0           0    2    11  74.3        16    0.0    0.0   10.67   18.67  28.0   \n",
       "1           1    3    11  81.3        18    1.0    4.5   22.00   31.00  20.0   \n",
       "2           2    3    11  81.3        18    1.0    6.0   19.00   30.00  24.0   \n",
       "\n",
       "  ...  PTRACCAT_Black  PTRACCAT_Hawaiian/Other PI  PTRACCAT_More than one  \\\n",
       "0 ...             0.0                         0.0                     0.0   \n",
       "1 ...             0.0                         0.0                     0.0   \n",
       "2 ...             0.0                         0.0                     0.0   \n",
       "\n",
       "   PTRACCAT_Unknown  PTRACCAT_White  PTMARRY_Married  PTMARRY_Never married  \\\n",
       "0               0.0             1.0              1.0                    0.0   \n",
       "1               0.0             1.0              1.0                    0.0   \n",
       "2               0.0             1.0              1.0                    0.0   \n",
       "\n",
       "   PTMARRY_Unknown  PTMARRY_Widowed  AD  \n",
       "0              0.0              0.0   0  \n",
       "1              0.0              0.0   1  \n",
       "2              0.0              0.0   1  \n",
       "\n",
       "[3 rows x 104 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix Size:\n",
      "-----------------------\n",
      "(12736, 104)\n",
      " \n",
      "Identified columns of interest in input file: \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Patient RID column: [1]\n",
      "Demo columns: [  3   4  90  91  92  93  94  95  96  97  98  99 100 101 102]\n",
      "BaselineOneTime columns: [ 5 54 84 85 86 87 88 89]\n",
      "BaselineEvaluation columns: [30 31 32 33 35 36 37 34 38 39 41 42 43 44 45 40 46 48 49 50 51 52 47 53]\n",
      "Time columns: [ 2 55 56 57 58 59 60 82 83]\n",
      "CurrentEvaluation columns: [ 6  7  8  9 11 12 13 10 14 15 17 18 19 20 21 16 22 24 25 26 27 28 23 29]\n",
      "CurrentDiagnosis columns: [103]\n",
      "------\n",
      "Method 2 for Longitudinal Data Analysis\n",
      "------\n",
      " \n",
      "New Input Matrix Size:\n",
      "-----------------------\n",
      "(1737, 120)\n",
      " \n",
      "New Output Matrix Size:\n",
      "-----------------------\n",
      "(1737,)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Longitudinal Data Analysis\n",
    "# -------------------------------\n",
    "\n",
    "# Input file name for Longitudinal Data Analysis\n",
    "InputToLongitudinal='CategoricalToNumerical.csv'\n",
    "\n",
    "with open(InputToLongitudinal) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    labels = next(reader)\n",
    "\n",
    "# Output file name from this script\n",
    "OutputFromLongitudinal='LongitudinalDataAnalysis.csv'\n",
    "\n",
    "# Patient RID Features\n",
    "Patient_FEATURES=['RID'];\n",
    "\n",
    "# Demographic Features\n",
    "Demo_FEATURES_type=['AGE','PTEDUCAT','PTGENDER','PTETHCAT','PTRACCAT','PTMARRY']\n",
    "Demo_FEATURES = []\n",
    "for i in labels:\n",
    "    if i in Demo_FEATURES_type:\n",
    "        Demo_FEATURES.append(i)\n",
    "    elif i.find(\"_\") != -1 and i[:i.find(\"_\")] in Demo_FEATURES_type:\n",
    "        Demo_FEATURES.append(i)\n",
    "    \n",
    "# Baseline OneTime Features\n",
    "BaselineOneTime_FEATURES_type = ['APOE4','Years_bl','DX_bl','ORIGPROT']\n",
    "BaselineOneTime_FEATURES = []\n",
    "for i in labels:\n",
    "    if i in BaselineOneTime_FEATURES_type:\n",
    "        BaselineOneTime_FEATURES.append(i)\n",
    "    elif i.rfind(\"_\") != -1 and i[:i.rfind(\"_\")] in BaselineOneTime_FEATURES_type:\n",
    "        BaselineOneTime_FEATURES.append(i)\n",
    "        \n",
    "# Time Headers\n",
    "Time_FEATURES_type=['SITE','Month','update_stamp_minus_EXAMDATE_bl','update_stamp_minus_EXAMDATE','EXAMDATE_minus_EXAMDATE_bl',\n",
    "               'COLPROT','M','Month_bl']\n",
    "Time_FEATURES = []\n",
    "for i in labels:\n",
    "    if i in Time_FEATURES_type:\n",
    "        Time_FEATURES.append(i)\n",
    "    elif i.find(\"_\") != -1 and i[:i.find(\"_\")] in Time_FEATURES_type:\n",
    "        Time_FEATURES.append(i)\n",
    "Time_FEATURES.insert(len(Time_FEATURES), Time_FEATURES.pop(Time_FEATURES.index('Month_bl'))) # Month_bl must be last feature in this list\n",
    "\n",
    "        \n",
    "# Baseline Evaluation Features\n",
    "BaselineEvaluation_FEATURES=['CDRSB_bl','ADAS11_bl','ADAS13_bl','MMSE_bl','RAVLT_learning_bl','RAVLT_forgetting_bl',\n",
    "                             'RAVLT_perc_forgetting_bl','RAVLT_immediate_bl','FAQ_bl','MOCA_bl','EcogPtLang_bl','EcogPtVisspat_bl',\n",
    "                             'EcogPtPlan_bl','EcogPtOrgan_bl','EcogPtDivatt_bl','EcogPtMem_bl','EcogPtTotal_bl','EcogSPLang_bl',\n",
    "                             'EcogSPVisspat_bl','EcogSPPlan_bl','EcogSPOrgan_bl','EcogSPDivatt_bl','EcogSPMem_bl','EcogSPTotal_bl'];\n",
    "\n",
    "\n",
    "   \n",
    "# Current Medical Evaluation\n",
    "CurrentEvaluation_FEATURES=['CDRSB','ADAS11','ADAS13','MMSE','RAVLT_learning','RAVLT_forgetting','RAVLT_perc_forgetting','RAVLT_immediate',\n",
    "                            'FAQ','MOCA','EcogPtLang','EcogPtVisspat','EcogPtPlan','EcogPtOrgan','EcogPtDivatt','EcogPtMem','EcogPtTotal',\n",
    "                            'EcogSPLang','EcogSPVisspat','EcogSPPlan','EcogSPOrgan','EcogSPDivatt','EcogSPMem','EcogSPTotal'];\n",
    "\n",
    "\n",
    "# Current Diagnosis\n",
    "CurrentDiagnosis_FEATURES= ['AD'];\n",
    "\n",
    "# Longitudinal Method\n",
    "LongitudinalMethod=2;\n",
    "MetricList=['MaxTime','Delta','Mean','Std'];\n",
    "\n",
    "# Run Longitudinal Data Anaysis\n",
    "LongitudinalDataAnalysis.runLongitudinal(InputToLongitudinal,OutputFromLongitudinal,Patient_FEATURES,Demo_FEATURES,\\\n",
    "                                         BaselineOneTime_FEATURES,Time_FEATURES,BaselineEvaluation_FEATURES,\\\n",
    "                                         CurrentEvaluation_FEATURES,CurrentDiagnosis_FEATURES,LongitudinalMethod,MetricList)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># RID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTGENDER_Male</th>\n",
       "      <th>PTETHCAT_Not Hisp/Latino</th>\n",
       "      <th>PTETHCAT_Unknown</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>...</th>\n",
       "      <th>EcogSPDivatt_Std</th>\n",
       "      <th>EcogSPMem_MaxTime</th>\n",
       "      <th>EcogSPMem_Delta</th>\n",
       "      <th>EcogSPMem_Mean</th>\n",
       "      <th>EcogSPMem_Std</th>\n",
       "      <th>EcogSPTotal_MaxTime</th>\n",
       "      <th>EcogSPTotal_Delta</th>\n",
       "      <th>EcogSPTotal_Mean</th>\n",
       "      <th>EcogSPTotal_Std</th>\n",
       "      <th>Diagnostics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>419.0</td>\n",
       "      <td>70.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132455</td>\n",
       "      <td>1.343750</td>\n",
       "      <td>0.162380</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.199948</td>\n",
       "      <td>1.264845</td>\n",
       "      <td>0.065282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619.0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28318</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>0.132455</td>\n",
       "      <td>2.186072</td>\n",
       "      <td>0.254667</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.199948</td>\n",
       "      <td>1.881981</td>\n",
       "      <td>0.195019</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28318</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>0.132455</td>\n",
       "      <td>2.186072</td>\n",
       "      <td>0.254667</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.199948</td>\n",
       "      <td>1.881981</td>\n",
       "      <td>0.195019</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   # RID   AGE  PTEDUCAT  PTGENDER_Male  PTETHCAT_Not Hisp/Latino  \\\n",
       "0  419.0  70.2      18.0            1.0                       1.0   \n",
       "1  619.0  77.5      12.0            1.0                       1.0   \n",
       "2  814.0  71.0      16.0            0.0                       1.0   \n",
       "\n",
       "   PTETHCAT_Unknown  PTRACCAT_Asian  PTRACCAT_Black  \\\n",
       "0               0.0             0.0             0.0   \n",
       "1               0.0             0.0             0.0   \n",
       "2               0.0             0.0             0.0   \n",
       "\n",
       "   PTRACCAT_Hawaiian/Other PI  PTRACCAT_More than one     ...       \\\n",
       "0                         0.0                     0.0     ...        \n",
       "1                         0.0                     0.0     ...        \n",
       "2                         0.0                     0.0     ...        \n",
       "\n",
       "   EcogSPDivatt_Std  EcogSPMem_MaxTime  EcogSPMem_Delta  EcogSPMem_Mean  \\\n",
       "0           0.00000           0.000000         0.132455        1.343750   \n",
       "1           0.28318           0.034314         0.132455        2.186072   \n",
       "2           0.28318           0.034314         0.132455        2.186072   \n",
       "\n",
       "   EcogSPMem_Std  EcogSPTotal_MaxTime  EcogSPTotal_Delta  EcogSPTotal_Mean  \\\n",
       "0       0.162380              0.00000           0.199948          1.264845   \n",
       "1       0.254667              0.03321           0.199948          1.881981   \n",
       "2       0.254667              0.03321           0.199948          1.881981   \n",
       "\n",
       "   EcogSPTotal_Std  Diagnostics  \n",
       "0         0.065282          0.0  \n",
       "1         0.195019          1.0  \n",
       "2         0.195019          1.0  \n",
       "\n",
       "[3 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># RID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTGENDER_Male</th>\n",
       "      <th>PTETHCAT_Not Hisp/Latino</th>\n",
       "      <th>PTETHCAT_Unknown</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other PI</th>\n",
       "      <th>PTRACCAT_More than one</th>\n",
       "      <th>...</th>\n",
       "      <th>EcogSPDivatt_Std</th>\n",
       "      <th>EcogSPMem_MaxTime</th>\n",
       "      <th>EcogSPMem_Delta</th>\n",
       "      <th>EcogSPMem_Mean</th>\n",
       "      <th>EcogSPMem_Std</th>\n",
       "      <th>EcogSPTotal_MaxTime</th>\n",
       "      <th>EcogSPTotal_Delta</th>\n",
       "      <th>EcogSPTotal_Mean</th>\n",
       "      <th>EcogSPTotal_Std</th>\n",
       "      <th>Diagnostics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>899.0</td>\n",
       "      <td>80.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283180</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>0.132455</td>\n",
       "      <td>2.186072</td>\n",
       "      <td>0.254667</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.199948</td>\n",
       "      <td>1.881981</td>\n",
       "      <td>0.195019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4194.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>0.548435</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>1.274957</td>\n",
       "      <td>0.139251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>579.0</td>\n",
       "      <td>65.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283180</td>\n",
       "      <td>0.034314</td>\n",
       "      <td>0.132455</td>\n",
       "      <td>2.186072</td>\n",
       "      <td>0.254667</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.199948</td>\n",
       "      <td>1.881981</td>\n",
       "      <td>0.195019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    # RID   AGE  PTEDUCAT  PTGENDER_Male  PTETHCAT_Not Hisp/Latino  \\\n",
       "0   899.0  80.1      16.0            0.0                       1.0   \n",
       "1  4194.0  62.0      16.0            1.0                       1.0   \n",
       "2   579.0  65.4      18.0            0.0                       1.0   \n",
       "\n",
       "   PTETHCAT_Unknown  PTRACCAT_Asian  PTRACCAT_Black  \\\n",
       "0               0.0             0.0             0.0   \n",
       "1               0.0             0.0             0.0   \n",
       "2               0.0             0.0             0.0   \n",
       "\n",
       "   PTRACCAT_Hawaiian/Other PI  PTRACCAT_More than one     ...       \\\n",
       "0                         0.0                     0.0     ...        \n",
       "1                         0.0                     0.0     ...        \n",
       "2                         0.0                     0.0     ...        \n",
       "\n",
       "   EcogSPDivatt_Std  EcogSPMem_MaxTime  EcogSPMem_Delta  EcogSPMem_Mean  \\\n",
       "0          0.283180           0.034314         0.132455        2.186072   \n",
       "1          0.272431           0.000000        -0.125000        1.687500   \n",
       "2          0.283180           0.034314         0.132455        2.186072   \n",
       "\n",
       "   EcogSPMem_Std  EcogSPTotal_MaxTime  EcogSPTotal_Delta  EcogSPTotal_Mean  \\\n",
       "0       0.254667              0.03321           0.199948          1.881981   \n",
       "1       0.548435              0.00000           0.011780          1.274957   \n",
       "2       0.254667              0.03321           0.199948          1.881981   \n",
       "\n",
       "   EcogSPTotal_Std  Diagnostics  \n",
       "0         0.195019          0.0  \n",
       "1         0.139251          0.0  \n",
       "2         0.195019          0.0  \n",
       "\n",
       "[3 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for imp in ['meanmode', 'knn']:\n",
    "    for feat in ['none','SVD','AffinityPropagation']:\n",
    "        log = []\n",
    "        rf  = []\n",
    "        mlp = []\n",
    "        grad = []\n",
    "        svm = []\n",
    "        log_p = []\n",
    "        rf_p  = []\n",
    "        mlp_p = []\n",
    "        grad_p = []\n",
    "        svm_p = []\n",
    "        for i in range(50):\n",
    "            TrainTestSplit.traintest_split(0.33)\n",
    "\n",
    "            Imputation.imputation(imp)\n",
    "\n",
    "            # ----------------------------------\n",
    "            # Feature Reduction \n",
    "            # ----------------------------------\n",
    "\n",
    "            # Input and Output files from Feature Reduction for train set\n",
    "            InputToFeatureReduction_train     ='ImputedMatrix_train.csv'\n",
    "            OutputFromFeatureReduction_train  ='Features_train.csv'\n",
    "            InputToFeatureReduction_test      ='ImputedMatrix_test.csv'\n",
    "            OutputFromFeatureReduction_test   ='Features_test.csv'\n",
    "\n",
    "\n",
    "            # Normalization method\n",
    "            NormalizationMethod='MinMax'\n",
    "            #NormalizationMethod='MeanStd'\n",
    "\n",
    "            # Feature Reduction Method and Settings\n",
    "            #FeatureReductionMethod='SVD'; \n",
    "            ExplainedVariance=0.99; # For method 'SVD'\n",
    "\n",
    "            FeatureReductionMethod= feat; \n",
    "            APpreference=-50; # Hyperparameter for method 'AffinityPropagation'\n",
    "\n",
    "\n",
    "            # Run Feature Reduction\n",
    "            FeatureReduction.RunFeatureReduction(InputToFeatureReduction_train,OutputFromFeatureReduction_train,\\\n",
    "                                                 InputToFeatureReduction_test,OutputFromFeatureReduction_test,\\\n",
    "                                                 NormalizationMethod,FeatureReductionMethod,ExplainedVariance,APpreference)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ##Models\n",
    "            #parameters = {'C': [0.001,0.01,0.1,0.5,1, 5], 'penalty': ['l1','l2']}\n",
    "            #model = \"LogisticRegression\"\n",
    "            #result = SupervisedLearning.TuneAndReport(model, parameters, 5, 'recall')\n",
    "            #log_p.append(result)\n",
    "            #log.append(ModelPerformance.model_performance('all'))\n",
    "\n",
    "\n",
    "            #parameters = {'n_estimators': [10,100,200,500,1000]}\n",
    "            #model = \"RandomForest\"\n",
    "            #result = SupervisedLearning.TuneAndReport(model, parameters, 5, 'recall')\n",
    "            #rf_p.append(result)\n",
    "            #rf.append(ModelPerformance.model_performance('all'))\n",
    "\n",
    "\n",
    "            parameters = {'alpha': [0.001, 0.01, 0.1, 1, 5], 'hidden_layer_sizes': [(100,), (100,100)] }\n",
    "            model = \"MLP\"\n",
    "            result = SupervisedLearning.TuneAndReport(model, parameters, 5, 'recall')\n",
    "            mlp_p.append(result)\n",
    "            mlp.append(ModelPerformance.model_performance('all'))\n",
    "            print i\n",
    "\n",
    "            #parameters = {'C': [0.001,0.01,0.1,0.5,1, 5], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'probability': [True]}\n",
    "            #model = \"SVM\"\n",
    "            #result = SupervisedLearning.TuneAndReport(model, parameters, 5, 'recall')\n",
    "            #svm_p.append(result)\n",
    "            #svm.append(ModelPerformance.model_performance('all'))\n",
    "\n",
    "\n",
    "            #parameters = {'n_estimators' : range(10, 800, 50)}\n",
    "            #model = \"GradientBoosting\"\n",
    "            #result = SupervisedLearning.TuneAndReport(model, parameters, 5, 'recall')\n",
    "            #grad_p.append(result)\n",
    "            #grad.append(ModelPerformance.model_performance('all'))\n",
    "            \n",
    "        with open(str(imp)+\"_\"+str(feat)+\".csv\", 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            #writer.writerow(['log',log_p,log])\n",
    "            #writer.writerow(['rf',rf_p,rf])\n",
    "            writer.writerow(['mlp',mlp_p,mlp])\n",
    "            #writer.writerow(['svm',svm_p,svm])\n",
    "            #writer.writerow(['grad',grad_p,grad])\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
