{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "import collections\n",
    "import csv\n",
    "import pandas as pd \n",
    "from scipy.stats import mode\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import cvxpy #conda install -c cvxgrp cvxpy\n",
    "import itertools\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: LongitudinalDataAnalysis.csv\n",
    "\n",
    "Ouput: ImputedMatrix.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imputation_mean_mode(data_train, data_test):\n",
    "    \"\"\"Function that provides imputation by mean for numeric columns and most frequent value for categorical columns\n",
    "    Imputes test data using mean/mode of the respective training set columns\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_train: training data as returned from longitudinal function\n",
    "    data_test: test data as returned from longitudinal function\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    Saves csv matrix \"ImputedMatrix_train.csv\" and \"ImputedMatrix_test.csv\"\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    If column is completely empty, drops it \n",
    "    \"\"\"\n",
    "    \n",
    "    for column in data_train:\n",
    "        data_train[column] = data_train[column].apply(pd.to_numeric)\n",
    "          \n",
    "        #if the column empty\n",
    "        if pd.isnull(data_train[column]).all():\n",
    "            del data_train[column]    \n",
    "            del data_test[column] \n",
    "            \n",
    "        #if this is a categorical column\n",
    "        elif np.array_equal(data_train[column].unique(),[0,1]):\n",
    "            data_train[column] = data_train[column].replace(np.nan, data_train[column].value_counts()[0])\n",
    "            data_test[column] = data_test[column].replace(np.nan, data_train[column].value_counts()[0])\n",
    "\n",
    "        else: #if numerical column\n",
    "            data_train[column] = data_train[column].replace(np.nan, data_train[column].mean()) \n",
    "            data_test[column] = data_test[column].replace(np.nan, data_train[column].mean()) \n",
    "          \n",
    "    data_train.to_csv(\"ImputedMatrix_train.csv\", index = False)\n",
    "    data_test.to_csv(\"ImputedMatrix_test.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through rows. If there is missing data in a row (say col 1 and col 4 are missing), find the nearest neighbor to this row by considering all the columns besides 1 and 4 and all the complete rows. To impute data in col 1, try to find 10 nearest neigbors's col 1 value that are non-NaN and take mean/mode depending on the type of column. Imputing does not happen in place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imputation_knn(data_train, data_test):\n",
    "    \"\"\"Function that provides imputation by kNN- takes the mean/mode of the values for 10 nearest neighbors (if possible) with valid data \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_train: training data as returned from longitudinal function\n",
    "    data_test: test data as returned from longitudinal function\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    Saves csv matrix \"ImputedMatrix_train.csv\" and \"ImputedMatrix_test.csv\"\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    If column is completely empty, drops it \n",
    "    \"\"\"\n",
    "\n",
    "    #add index column so that original row numbers are maintained \n",
    "    data_train['INDEX'] = range(len(data_train))\n",
    "    \n",
    "    #deletes any columns that are empty in training set\n",
    "    for column in data_train:\n",
    "        if pd.isnull(data_train[column]).all():\n",
    "            del data_train[column] \n",
    "            del data_test[column] \n",
    "           \n",
    "    matrix = data_train.as_matrix()\n",
    "    complete_matrix = np.copy(matrix)\n",
    "    \n",
    "    for x in xrange(matrix.shape[0]):\n",
    "        if np.isnan(matrix[x]).any(): #if we need to impute for this row\n",
    "            \n",
    "            #figure out which columns have nan's for this row \n",
    "            indices_to_impute = list(np.transpose(np.argwhere(np.isnan(matrix[x])))[0])\n",
    "            \n",
    "            ######\n",
    "            #In terms of kNN input, drop columns that are missing for this example, drop the test example row \n",
    "            #itself, and drop any rows that still have missing data\n",
    "            ######\n",
    "            training_X = np.delete(matrix, indices_to_impute, axis=1) #drop columns that are missing for this example\n",
    "            test_example = training_X[x]\n",
    "            training_X = np.delete(training_X, x, axis = 0) #drop the test example\n",
    "            training_X = training_X[~np.isnan(training_X).any(axis=1)] #drop the rows with missing data \n",
    "            \n",
    "            neigh = NearestNeighbors(n_neighbors=len(training_X)-1)\n",
    "            \n",
    "            #model inputs- ignore last \"Index\" Column and 2nd to last Diagnoistics column\n",
    "            model_X = training_X[:,:-2]\n",
    "            model_Y = test_example[:-2]\n",
    "            \n",
    "            #fit model and find nearest neighbors indices\n",
    "            neigh.fit(model_X) \n",
    "            ans = neigh.kneighbors([model_Y])[1][0] #these are the indices\n",
    "            \n",
    "            #iterate over each entry in row that needs imputing\n",
    "            for index in indices_to_impute:\n",
    "                i = 0\n",
    "                neighbors = []                            \n",
    "                true_row = int(training_X[ans[i],-1]) #recover \"true\" index (before things were deleted)\n",
    " \n",
    "                #get 10 (if possible) nearest neighbor values that are non-Nan\n",
    "                while i < len(ans) and len(neighbors) < 11:\n",
    "                    if not np.isnan(matrix[true_row,index]):\n",
    "                        neighbors.append(matrix[true_row,index])\n",
    "                    \n",
    "                    i += 1\n",
    "                    true_row = int(training_X[ans[i],-1])\n",
    "                \n",
    "                #fill with mode of neighbors if categorical column\n",
    "                if np.array_equal(set(neighbors),[0,1]):\n",
    "                    complete_matrix[x,index] = neighbors.value_counts()[0]\n",
    "                \n",
    "                else: #fill with mean of neighbors if numerical column\n",
    "                    complete_matrix[x,index] = np.mean(neighbors)\n",
    "    \n",
    "    \n",
    "    ################## Now impute test set #####################\n",
    "    #complete matrix has the training data\n",
    "    \n",
    "    matrix_test = data_test.as_matrix()\n",
    "    complete_matrix_test = np.copy(matrix_test)\n",
    "    \n",
    "    for x in xrange(matrix_test.shape[0]):\n",
    "        if np.isnan(matrix_test[x]).any(): #if we need to impute for this row\n",
    "            \n",
    "            #figure out which columns have nan's for this row \n",
    "            indices_to_impute = list(np.transpose(np.argwhere(np.isnan(matrix_test[x])))[0])\n",
    "            \n",
    "            ######\n",
    "            #In terms of kNN input, drop training columns that are missing for this example, drop the test example row \n",
    "            #itself, and drop any rows that still have missing data\n",
    "            ######\n",
    "            training_X = np.delete(complete_matrix, indices_to_impute, axis=1) #drop columns that are missing for this example\n",
    "            test_example = np.delete(matrix_test, indices_to_impute, axis=1)\n",
    "            test_example = test_example[x]\n",
    "            \n",
    "            neigh = NearestNeighbors(n_neighbors=len(training_X)-1)\n",
    "    \n",
    "            #model inputs- ignore last \"Index\" Column and 2nd to last Diagnoistics column\n",
    "            model_X = training_X[:,:-2]\n",
    "            model_Y = test_example[:-1]\n",
    "            \n",
    "            #fit model and find nearest neighbors indices\n",
    "            neigh.fit(model_X) \n",
    "            ans = neigh.kneighbors([model_Y])[1][0] #these are the indices\n",
    "    \n",
    "            #iterate over each entry in row that needs imputing\n",
    "            for index in indices_to_impute:\n",
    "                i = 0\n",
    "                neighbors = []                            \n",
    "                true_row = int(training_X[ans[i],-1]) #recover \"true\" index (before things were deleted)\n",
    " \n",
    "                #get 10 (if possible) nearest neighbor values that are non-Nan\n",
    "                while i < len(ans) and len(neighbors) < 11:\n",
    "                    if not np.isnan(complete_matrix[true_row,index]):\n",
    "                        neighbors.append(complete_matrix[true_row,index])\n",
    "                    \n",
    "                    i += 1\n",
    "                    true_row = int(training_X[ans[i],-1])\n",
    "                \n",
    "                #fill with mode of neighbors if categorical column\n",
    "                if np.array_equal(set(neighbors),[0,1]):\n",
    "                    complete_matrix_test[x,index] = neighbors.value_counts()[0]\n",
    "                \n",
    "                else: #fill with mean of neighbors if numerical column\n",
    "                    complete_matrix_test[x,index] = np.mean(neighbors)\n",
    "    \n",
    "    \n",
    "    #convert Training data to DataFrame, delete Index column and Save\n",
    "    data = pd.DataFrame(data=complete_matrix[:,:],  \n",
    "                 columns=list(data_train))  \n",
    "    \n",
    "    del data['INDEX']\n",
    "    data.to_csv(\"ImputedMatrix_train.csv\", index = False)\n",
    "    \n",
    "    \n",
    "    #convert Testing data to DataFrame, Save\n",
    "    data = pd.DataFrame(data=complete_matrix_test[:,:],  \n",
    "                 columns=list(data_test))  \n",
    "    \n",
    "    data.to_csv(\"ImputedMatrix_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_random_column_samples(column):\n",
    "    col_mask = np.isnan(column)\n",
    "    n_missing = np.sum(col_mask)\n",
    "    \n",
    "    if n_missing == len(column):\n",
    "        return np.zeros_like(column)\n",
    "\n",
    "    mean = np.nanmean(column)\n",
    "    std = np.nanstd(column)        \n",
    "    \n",
    "    return np.random.randn(n_missing) * std + mean\n",
    "\n",
    "\n",
    "def imputation_convexOptimization(data_train, data_test): \n",
    "    \"\"\"Function that provides imputation using exact matrix completion via convex optimization\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data: data as returned from longitudinal function\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    Saves csv matrix \"ImputedMatrix.csv\" \n",
    "    \"\"\"\n",
    "    #model inputs- ignore last Diagnoistics column\n",
    "    data_train = data_train.ix[:,:-1]\n",
    "    data_test = data_test.ix[:,:-1]\n",
    "    \n",
    "    #deletes any columns that are empty in training set\n",
    "    for column in data_train:\n",
    "        if pd.isnull(data_train[column]).all():\n",
    "            del data_train[column] \n",
    "            del data_test[column] \n",
    "           \n",
    "    matrix = data_train.as_matrix()\n",
    "    complete_matrix = np.copy(matrix)\n",
    "    \n",
    "    X_incomplete = matrix\n",
    "    X = np.asarray(X_incomplete)\n",
    "    error_tolerance=0.0001\n",
    "    missing_mask = np.isnan(X)\n",
    "    for col_idx in range(X.shape[1]):\n",
    "        missing_col = missing_mask[:, col_idx]\n",
    "        n_missing = missing_col.sum()\n",
    "        if n_missing == 0:\n",
    "            continue\n",
    "        col_data = X[:, col_idx]\n",
    "        fill_values = generate_random_column_samples(col_data)\n",
    "        X[missing_col, col_idx] = fill_values\n",
    "    m, n = X.shape   \n",
    "    \n",
    "    S = cvxpy.Variable(m, n, name=\"S\")\n",
    "    \n",
    "    ok_mask = ~missing_mask\n",
    "    masked_X = cvxpy.mul_elemwise(ok_mask, X)\n",
    "    masked_S = cvxpy.mul_elemwise(ok_mask, S)\n",
    "    \n",
    "    abs_diff = cvxpy.abs(masked_S - masked_X)\n",
    "    close_to_data = abs_diff <= error_tolerance\n",
    "    constraints = [close_to_data]\n",
    "    print constraints\n",
    "    \n",
    "    norm = cvxpy.norm(S, \"nuc\")\n",
    "    objective = cvxpy.Minimize(norm)\n",
    "    \n",
    "    problem = cvxpy.Problem(objective, constraints)\n",
    "    problem.solve(verbose = True, solver=cvxpy.SCS)\n",
    "    \n",
    "    complete_matrix_train = S.value\n",
    "    \n",
    "    ol = data_train\n",
    "    data = pd.DataFrame(data=complete_matrix_train[:,:],  \n",
    "                 columns=list(data_train))  \n",
    "    cols_missing = (ol.columns)[pd.isnull(ol).sum() > 0]\n",
    "    col_uniq = []\n",
    "    for column in cols_missing:\n",
    "        if np.unique(ol[column][~ol[column].isnull()]).sum() < 20:\n",
    "            col_uniq.append(column)\n",
    "    col_uniq_int = []\n",
    "    for i in col_uniq:\n",
    "        if len(str(np.unique(ol[i])[0])) < 6:\n",
    "            col_uniq_int.append(i) \n",
    "    col_uniq_int = col_uniq_int[0:5]\n",
    "    for col in col_uniq_int:\n",
    "        for i in data[col][ol[col].isnull()].index:\n",
    "            x = data[col][ol[col].isnull()][i]\n",
    "            if int((x*10) % 10) < 5:\n",
    "                data.set_value(i, col, math.floor(x))\n",
    "            else:\n",
    "                data.set_value(i, col, math.ceil(x))\n",
    "    for column in cols_missing:\n",
    "        ol[column][ol[column].isnull()] = data[column][ol[column].isnull()]\n",
    "        \n",
    "   \n",
    "    ol.to_csv(\"ImputedMatrix_train.csv\", index = False)\n",
    "                \n",
    "    ################## Now impute test set #####################\n",
    "    #complete matrix has the training data\n",
    "    \n",
    "    #add index column so that original row numbers are maintained \n",
    "    matrix_test = data_test.as_matrix()\n",
    "    complete_matrix_test = np.copy(matrix_test)\n",
    "    \n",
    "    X_incomplete = matrix_test\n",
    "    X = np.asarray(X_incomplete)\n",
    "    error_tolerance=0.0001\n",
    "    missing_mask = np.isnan(X)\n",
    "    for col_idx in range(X.shape[1]):\n",
    "            missing_col = missing_mask[:, col_idx]\n",
    "            n_missing = missing_col.sum()\n",
    "            if n_missing == 0:\n",
    "                continue\n",
    "            col_data = X[:, col_idx]\n",
    "            fill_values = generate_random_column_samples(col_data)\n",
    "            X[missing_col, col_idx] = fill_values\n",
    "    m, n = X.shape   \n",
    "    \n",
    "    S = cvxpy.Variable(m, n, name=\"S\")\n",
    "    \n",
    "    ok_mask = ~missing_mask\n",
    "    masked_X = cvxpy.mul_elemwise(ok_mask, X)\n",
    "    masked_S = cvxpy.mul_elemwise(ok_mask, S)\n",
    "    \n",
    "    abs_diff = cvxpy.abs(masked_S - masked_X)\n",
    "    close_to_data = abs_diff <= error_tolerance\n",
    "    constraints = [close_to_data]\n",
    "    print constraints\n",
    "    \n",
    "    norm = cvxpy.norm(S, \"nuc\")\n",
    "    objective = cvxpy.Minimize(norm)\n",
    "    \n",
    "    problem = cvxpy.Problem(objective, constraints)\n",
    "    problem.solve(verbose = True, solver=cvxpy.SCS)\n",
    "    \n",
    "    complete_matrix_test = S.value\n",
    "\n",
    "    ol = data_test\n",
    "    data = pd.DataFrame(data=complete_matrix_test[:,:],  \n",
    "                 columns=list(data_test))  \n",
    "    cols_missing = (ol.columns)[pd.isnull(ol).sum() > 0]\n",
    "    col_uniq = []\n",
    "    for column in cols_missing:\n",
    "        if np.unique(ol[column][~ol[column].isnull()]).sum() < 20:\n",
    "            col_uniq.append(column)\n",
    "    col_uniq_int = []\n",
    "    for i in col_uniq:\n",
    "        if len(str(np.unique(ol[i])[0])) < 6:\n",
    "            col_uniq_int.append(i) \n",
    "    col_uniq_int = col_uniq_int[0:5]\n",
    "    for col in col_uniq_int:\n",
    "        for i in data[col][ol[col].isnull()].index:\n",
    "            x = data[col][ol[col].isnull()][i]\n",
    "            if int((x*10) % 10) < 5:\n",
    "                data.set_value(i, col, math.floor(x))\n",
    "            else:\n",
    "                data.set_value(i, col, math.ceil(x))\n",
    "    for column in cols_missing:\n",
    "        ol[column][ol[column].isnull()] = data[column][ol[column].isnull()]\n",
    "    \n",
    "    ol.to_csv(\"ImputedMatrix_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def soft_impute(data_train, data_test):\n",
    "    \"\"\"\n",
    "    Implementation of the SoftImpute algorithm via spectral regularization algorithm\n",
    "    \"\"\"\n",
    "    #model inputs- ignore last Diagnoistics column\n",
    "    data_train = data_train.ix[:,:-1]\n",
    "    data_test = data_test.ix[:,:-1]\n",
    "    \n",
    "    #deletes any columns that are empty in training set\n",
    "    for column in data_train:\n",
    "        if pd.isnull(data_train[column]).all():\n",
    "            del data_train[column] \n",
    "            del data_test[column] \n",
    "           \n",
    "    matrix = data_train.as_matrix()\n",
    "    complete_matrix = np.copy(matrix)\n",
    "    \n",
    "    X_incomplete = matrix\n",
    "    X = np.asarray(X_incomplete)\n",
    "    error_tolerance=0.0001\n",
    "    missing_mask = np.isnan(X)\n",
    "    \n",
    "    for col_idx in range(X.shape[1]):\n",
    "            missing_col = missing_mask[:, col_idx]\n",
    "            n_missing = missing_col.sum()\n",
    "            if n_missing == 0:\n",
    "                continue\n",
    "            col_data = X[:, col_idx]\n",
    "            fill_values = generate_random_column_samples(col_data)\n",
    "            X[missing_col, col_idx] = fill_values\n",
    "\n",
    "    X_init = X.copy()\n",
    "\n",
    "    X_filled = X \n",
    "    \n",
    "    observed_mask = ~missing_mask\n",
    "    _, s, _ = randomized_svd(\n",
    "        X_filled,\n",
    "        1,\n",
    "        n_iter=5)\n",
    "    max_singular_value = s[0]\n",
    "\n",
    "    shrinkage_value = max_singular_value / 50.0\n",
    "\n",
    "    max_iters=100\n",
    "    max_rank = None\n",
    "    for i in range(max_iters):\n",
    "        n_power_iterations=1\n",
    "        if max_rank:\n",
    "            (U, s, V) = randomized_svd(\n",
    "                X_filled,\n",
    "                max_rank = None,\n",
    "                n_iter=n_power_iterations)\n",
    "        else:\n",
    "            # perform a full rank SVD using ARPACK\n",
    "            (U, s, V) = np.linalg.svd(\n",
    "                X_filled,\n",
    "                full_matrices=False,\n",
    "                compute_uv=True)\n",
    "        s_thresh = np.maximum(s - shrinkage_value, 0)\n",
    "        rank = (s_thresh > 0).sum()\n",
    "        s_thresh = s_thresh[:rank]\n",
    "        U_thresh = U[:, :rank]\n",
    "        V_thresh = V[:rank, :]\n",
    "        S_thresh = np.diag(s_thresh)\n",
    "        X_reconstruction = np.dot(U_thresh, np.dot(S_thresh, V_thresh))\n",
    "        masked_diff = X_init[observed_mask] - X_reconstruction[observed_mask]\n",
    "        mae = np.mean(np.abs(masked_diff))\n",
    "        \n",
    "        X_old = X_filled\n",
    "        X_new=X_reconstruction\n",
    "        \n",
    "        old_missing_values = X_old[missing_mask]\n",
    "        new_missing_values = X_new[missing_mask]\n",
    "        \n",
    "        difference = old_missing_values - new_missing_values\n",
    "        \n",
    "        ssd = np.sum(difference ** 2)\n",
    "        old_norm = np.sqrt((old_missing_values ** 2).sum())\n",
    "        \n",
    "        convergence_threshold=0.001\n",
    "        converged = (np.sqrt(ssd) / old_norm) < convergence_threshold\n",
    "        \n",
    "        X_filled[missing_mask] = X_reconstruction[missing_mask]\n",
    "        \n",
    "        complete_matrix = X_filled\n",
    "    \n",
    "    ################## Now impute test set #####################\n",
    "    #complete matrix has the training data\n",
    "        \n",
    "    matrix_test = data_test.as_matrix()\n",
    "    complete_matrix_test = np.copy(matrix_test)\n",
    "    \n",
    "    X_incomplete = matrix_test\n",
    "    X = np.asarray(X_incomplete)\n",
    "    error_tolerance=0.0001\n",
    "    missing_mask = np.isnan(X)\n",
    "    \n",
    "    for col_idx in range(X.shape[1]):\n",
    "            missing_col = missing_mask[:, col_idx]\n",
    "            n_missing = missing_col.sum()\n",
    "            if n_missing == 0:\n",
    "                continue\n",
    "            col_data = X[:, col_idx]\n",
    "            fill_values = generate_random_column_samples(col_data)\n",
    "            X[missing_col, col_idx] = fill_values\n",
    "\n",
    "    X_init = X.copy()\n",
    "\n",
    "    X_filled = X \n",
    "    \n",
    "    observed_mask = ~missing_mask\n",
    "    _, s, _ = randomized_svd(\n",
    "        X_filled,\n",
    "        1,\n",
    "        n_iter=5)\n",
    "    max_singular_value = s[0]\n",
    "\n",
    "    shrinkage_value = max_singular_value / 50.0\n",
    "\n",
    "    max_iters=100\n",
    "    max_rank = None\n",
    "    for i in range(max_iters):\n",
    "        n_power_iterations=1\n",
    "        if max_rank:\n",
    "            (U, s, V) = randomized_svd(\n",
    "                X_filled,\n",
    "                max_rank = None,\n",
    "                n_iter=n_power_iterations)\n",
    "        else:\n",
    "            # perform a full rank SVD using ARPACK\n",
    "            (U, s, V) = np.linalg.svd(\n",
    "                X_filled,\n",
    "                full_matrices=False,\n",
    "                compute_uv=True)\n",
    "        s_thresh = np.maximum(s - shrinkage_value, 0)\n",
    "        rank = (s_thresh > 0).sum()\n",
    "        s_thresh = s_thresh[:rank]\n",
    "        U_thresh = U[:, :rank]\n",
    "        V_thresh = V[:rank, :]\n",
    "        S_thresh = np.diag(s_thresh)\n",
    "        X_reconstruction = np.dot(U_thresh, np.dot(S_thresh, V_thresh))\n",
    "        masked_diff = X_init[observed_mask] - X_reconstruction[observed_mask]\n",
    "        mae = np.mean(np.abs(masked_diff))\n",
    "        \n",
    "        X_old = X_filled\n",
    "        X_new=X_reconstruction\n",
    "        \n",
    "        old_missing_values = X_old[missing_mask]\n",
    "        new_missing_values = X_new[missing_mask]\n",
    "        \n",
    "        difference = old_missing_values - new_missing_values\n",
    "        \n",
    "        ssd = np.sum(difference ** 2)\n",
    "        old_norm = np.sqrt((old_missing_values ** 2).sum())\n",
    "        \n",
    "        convergence_threshold=0.001\n",
    "        converged = (np.sqrt(ssd) / old_norm) < convergence_threshold\n",
    "        \n",
    "        X_filled[missing_mask] = X_reconstruction[missing_mask]\n",
    "        \n",
    "        complete_matrix_test = X_filled\n",
    "        \n",
    "    #convert Training data to DataFrame, delete Index column and Save\n",
    "    data = pd.DataFrame(data=complete_matrix[:,:],  \n",
    "                 columns=list(data_train))  \n",
    "\n",
    "    data.to_csv(\"ImputedMatrix_train.csv\", index = False)\n",
    "    \n",
    "    \n",
    "    #convert Testing data to DataFrame, Save\n",
    "    data = pd.DataFrame(data=complete_matrix_test[:,:],  \n",
    "                 columns=list(data_test))  \n",
    "    \n",
    "    data.to_csv(\"ImputedMatrix_test.csv\", index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imputation(imputationType):\n",
    "    \"\"\" Driver imputation function\n",
    "    \n",
    "    imputationType: how to impute; \"meanmode\", 'knn', 'nuclearnorm' or 'softimpute'\n",
    "    \"\"\"\n",
    "    data_train = pd.read_csv(\"LongitudinalDataAnalysis_train.csv\")\n",
    "    data_test = pd.read_csv(\"LongitudinalDataAnalysis_test.csv\")\n",
    "    \n",
    "    if imputationType == \"meanmode\":\n",
    "        imputation_mean_mode(data_train, data_test)  \n",
    "        \n",
    "    if imputationType == 'knn':\n",
    "        imputation_knn(data_train, data_test)\n",
    "    \n",
    "    if imputationType == 'nuclearnorm':\n",
    "        imputation_convexOptimization(data_train, data_test)\n",
    "    \n",
    "    if imputationType == 'softimpute':\n",
    "        soft_impute(data_train, data_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "imputation('nuclearnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
